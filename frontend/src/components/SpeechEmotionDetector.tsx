import React, { useRef, useEffect, useState, useCallback } from 'react'
import { Mic, MicOff, Upload, Play, Square, AlertCircle } from 'lucide-react'
import { SpeechEmotionData, SpeechEmotionResult, AudioRecordingState } from '../types'
import { speechEmotionService } from '../services'

interface SpeechEmotionDetectorProps {
  onEmotionDetected: (emotions: SpeechEmotionData) => void
}

const SpeechEmotionDetector: React.FC<SpeechEmotionDetectorProps> = ({ onEmotionDetected }) => {
  const [recordingState, setRecordingState] = useState<AudioRecordingState>({
    isRecording: false,
    duration: 0,
    audioData: null,
    emotionResult: null
  })

  const [isConnected, setIsConnected] = useState(false)
  const [connectionError, setConnectionError] = useState<string | null>(null)
  const [isProcessing, setIsProcessing] = useState(false)
  const [uploadedFile, setUploadedFile] = useState<File | null>(null)

  const mediaRecorderRef = useRef<MediaRecorder | null>(null)
  const audioChunksRef = useRef<Blob[]>([])
  const streamRef = useRef<MediaStream | null>(null)
  const durationIntervalRef = useRef<NodeJS.Timeout | null>(null)

  // å¤„ç†è¯­éŸ³æƒ…ç»ªè¯†åˆ«ç»“æœ
  const handleSpeechEmotionResult = useCallback((result: SpeechEmotionResult) => {
    console.log('ğŸ¤ æ¥æ”¶åˆ°è¯­éŸ³æƒ…ç»ªè¯†åˆ«ç»“æœ:', result)

    // è½¬æ¢æ ¼å¼ä»¥é€‚é…ç°æœ‰çš„SpeechEmotionDataç±»å‹
    const emotionData: SpeechEmotionData = {
      happy: result.probabilities.happy || 0,
      sad: result.probabilities.sad || 0,
      angry: result.probabilities.anger || 0,
      surprised: result.probabilities.surprise || 0,
      neutral: result.probabilities.neutral || 0,
      disgust: result.probabilities.disgust || 0,
      fearful: result.probabilities.fearful || 0,
      timestamp: new Date()
    }

    setRecordingState(prev => ({
      ...prev,
      emotionResult: emotionData
    }))

    onEmotionDetected(emotionData)
  }, [onEmotionDetected])

  // å¤„ç†è¿æ¥çŠ¶æ€å˜åŒ–
  const handleConnectionChange = useCallback((connected: boolean) => {
    console.log('ğŸ”— è¯­éŸ³è¿æ¥çŠ¶æ€å˜åŒ–:', connected)
    setIsConnected(connected)
    if (!connected) {
      setConnectionError('è¯­éŸ³æœåŠ¡è¿æ¥å¤±è´¥')
    } else {
      setConnectionError(null)
    }
  }, [])

  // å¤„ç†è¿æ¥é”™è¯¯
  const handleError = useCallback((error: string) => {
    console.error('âŒ è¯­éŸ³è¯†åˆ«é”™è¯¯:', error)
    setConnectionError(error)
  }, [])

  // å¼€å§‹å½•éŸ³
  const startRecording = useCallback(async () => {
    try {
      console.log('ğŸ¤ å¼€å§‹å½•éŸ³...')

      // è¯·æ±‚éº¦å…‹é£æƒé™
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true
        }
      })

      streamRef.current = stream
      audioChunksRef.current = []

      // åˆ›å»ºMediaRecorder
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus'
      })

      mediaRecorderRef.current = mediaRecorder

      // è®¾ç½®æ•°æ®å¤„ç†
      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data)
        }
      }

      mediaRecorder.onstop = () => {
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' })
        setRecordingState(prev => ({
          ...prev,
          audioData: audioBlob,
          isRecording: false
        }))

        // åœæ­¢æ‰€æœ‰éŸ³è½¨
        if (streamRef.current) {
          streamRef.current.getTracks().forEach(track => track.stop())
        }

        console.log('ğŸ¤ å½•éŸ³ç»“æŸ')
      }

      // å¼€å§‹å½•éŸ³
      mediaRecorder.start(100) // æ¯100msæ”¶é›†ä¸€æ¬¡æ•°æ®

      setRecordingState(prev => ({
        ...prev,
        isRecording: true,
        duration: 0,
        audioData: null,
        emotionResult: null
      }))

      // å¼€å§‹è®¡æ—¶
      durationIntervalRef.current = setInterval(() => {
        setRecordingState(prev => ({
          ...prev,
          duration: prev.duration + 0.1
        }))
      }, 100)

      console.log('âœ… å½•éŸ³å·²å¼€å§‹')

    } catch (error) {
      console.error('âŒ å¯åŠ¨å½•éŸ³å¤±è´¥:', error)
      setConnectionError('æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®')
    }
  }, [])

  // åœæ­¢å½•éŸ³
  const stopRecording = useCallback(() => {
    console.log('ğŸ›‘ åœæ­¢å½•éŸ³')

    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      mediaRecorderRef.current.stop()
    }

    if (durationIntervalRef.current) {
      clearInterval(durationIntervalRef.current)
      durationIntervalRef.current = null
    }

    setRecordingState(prev => ({
      ...prev,
      isRecording: false
    }))
  }, [])

  // åˆ†æå½•éŸ³ç»“æœ
  const analyzeRecording = useCallback(async () => {
    if (!recordingState.audioData) {
      setConnectionError('æ²¡æœ‰å½•éŸ³æ•°æ®')
      return
    }

    setIsProcessing(true)
    setConnectionError(null)

    try {
      console.log('ğŸµ å¼€å§‹åˆ†æå½•éŸ³...')

      const result = await speechEmotionService.analyzeAudio(recordingState.audioData)
      handleSpeechEmotionResult(result)

      console.log('âœ… å½•éŸ³åˆ†æå®Œæˆ')

    } catch (error: any) {
      console.error('âŒ åˆ†æå½•éŸ³å¤±è´¥:', error)
      setConnectionError(error.message || 'åˆ†æå¤±è´¥')
    } finally {
      setIsProcessing(false)
    }
  }, [recordingState.audioData, handleSpeechEmotionResult])

  // å¤„ç†æ–‡ä»¶ä¸Šä¼ 
  const handleFileUpload = useCallback((event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0]
    if (file) {
      // æ£€æŸ¥æ–‡ä»¶ç±»å‹
      const allowedTypes = ['audio/wav', 'audio/mpeg', 'audio/mp3', 'audio/x-wav', 'audio/wave']
      if (!allowedTypes.includes(file.type)) {
        setConnectionError('ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼Œè¯·ä¸Šä¼  WAV æˆ– MP3 æ–‡ä»¶')
        return
      }

      // æ£€æŸ¥æ–‡ä»¶å¤§å° (é™åˆ¶ä¸º50MB)
      if (file.size > 50 * 1024 * 1024) {
        setConnectionError('æ–‡ä»¶è¿‡å¤§ï¼Œè¯·ä¸Šä¼ å°äº50MBçš„éŸ³é¢‘æ–‡ä»¶')
        return
      }

      setUploadedFile(file)
      setConnectionError(null)
      console.log('ğŸ“ æ–‡ä»¶å·²é€‰æ‹©:', file.name, file.size, 'bytes')
    }
  }, [])

  // åˆ†æä¸Šä¼ çš„æ–‡ä»¶
  const analyzeUploadedFile = useCallback(async () => {
    if (!uploadedFile) {
      setConnectionError('æ²¡æœ‰é€‰æ‹©æ–‡ä»¶')
      return
    }

    setIsProcessing(true)
    setConnectionError(null)

    try {
      console.log('ğŸ“ å¼€å§‹åˆ†æä¸Šä¼ æ–‡ä»¶...')

      const result = await speechEmotionService.analyzeAudioFile(uploadedFile)
      handleSpeechEmotionResult(result)

      console.log('âœ… æ–‡ä»¶åˆ†æå®Œæˆ')

    } catch (error: any) {
      console.error('âŒ åˆ†ææ–‡ä»¶å¤±è´¥:', error)
      setConnectionError(error.message || 'åˆ†æå¤±è´¥')
    } finally {
      setIsProcessing(false)
    }
  }, [uploadedFile, handleSpeechEmotionResult])

  // æ ¼å¼åŒ–æ—¶é•¿æ˜¾ç¤º
  const formatDuration = (seconds: number): string => {
    const mins = Math.floor(seconds / 60)
    const secs = Math.floor(seconds % 60)
    const ms = Math.floor((seconds % 1) * 10)
    return `${mins}:${secs.toString().padStart(2, '0')}.${ms}`
  }

  // è·å–ä¸»è¦æƒ…ç»ª
  const getPrimaryEmotion = (emotions: SpeechEmotionData): string => {
    const emotionEntries = Object.entries(emotions).filter(([key]) => key !== 'timestamp')
    return emotionEntries.reduce((max, current) =>
      current[1] > max[1] ? current : max
    )[0]
  }

  // è·å–æƒ…ç»ªæ ‡ç­¾
  const getEmotionLabel = (emotion: string): string => {
    const labels: Record<string, string> = {
      happy: 'å¼€å¿ƒ',
      sad: 'æ‚²ä¼¤',
      angry: 'æ„¤æ€’',
      surprised: 'æƒŠè®¶',
      neutral: 'å¹³é™',
      disgust: 'åŒæ¶',
      fearful: 'ææƒ§'
    }
    return labels[emotion] || emotion
  }

  // è·å–æƒ…ç»ªé¢œè‰²
  const getEmotionColor = (emotion: string): string => {
    const colors: Record<string, string> = {
      happy: 'text-green-600',
      sad: 'text-blue-600',
      angry: 'text-red-600',
      surprised: 'text-purple-600',
      neutral: 'text-gray-600',
      disgust: 'text-yellow-600',
      fearful: 'text-orange-600'
    }
    return colors[emotion] || 'text-gray-600'
  }

  return (
    <div className="bg-white dark:bg-gray-800 rounded-lg shadow-lg p-6">
      <div className="mb-6">
        <h2 className="text-2xl font-bold text-gray-900 dark:text-white mb-2">
          è¯­éŸ³æƒ…ç»ªç›‘æµ‹
        </h2>
        <div className="flex items-center space-x-2">
          {recordingState.isRecording && (
            <div className="flex items-center space-x-2">
              <div className="w-3 h-3 bg-red-500 rounded-full animate-pulse" />
              <span className="text-sm text-red-600">å½•éŸ³ä¸­...</span>
            </div>
          )}
          <div className="text-sm text-gray-600 dark:text-gray-300">
            çŠ¶æ€: {isConnected ? 'å·²è¿æ¥' : 'æœªè¿æ¥'} |
            æ—¶é•¿: {formatDuration(recordingState.duration)}
          </div>
        </div>
      </div>

      <div className="grid grid-cols-1 lg:grid-cols-2 gap-6">
        {/* å½•éŸ³æ§åˆ¶åŒºåŸŸ */}
        <div className="space-y-4">
          <div className="bg-gray-50 dark:bg-gray-700 p-4 rounded-lg">
            <h3 className="text-lg font-semibold text-gray-900 dark:text-white mb-4">
              å®æ—¶å½•éŸ³åˆ†æ
            </h3>

            <div className="flex items-center space-x-4 mb-4">
              <button
                onClick={recordingState.isRecording ? stopRecording : startRecording}
                className={`flex items-center space-x-2 px-4 py-2 rounded-lg font-medium ${
                  recordingState.isRecording
                    ? 'bg-red-600 hover:bg-red-700 text-white'
                    : 'bg-blue-600 hover:bg-blue-700 text-white'
                }`}
                disabled={isProcessing}
              >
                {recordingState.isRecording ? (
                  <>
                    <Square className="w-5 h-5" />
                    <span>åœæ­¢å½•éŸ³</span>
                  </>
                ) : (
                  <>
                    <Mic className="w-5 h-5" />
                    <span>å¼€å§‹å½•éŸ³</span>
                  </>
                )}
              </button>

              {recordingState.audioData && !recordingState.isRecording && (
                <button
                  onClick={analyzeRecording}
                  className="flex items-center space-x-2 px-4 py-2 bg-green-600 hover:bg-green-700 text-white rounded-lg font-medium"
                  disabled={isProcessing}
                >
                  <Play className="w-5 h-5" />
                  <span>{isProcessing ? 'åˆ†æä¸­...' : 'åˆ†æå½•éŸ³'}</span>
                </button>
              )}
            </div>

            {recordingState.audioData && (
              <div className="text-sm text-gray-600 dark:text-gray-300">
                å½•éŸ³æ–‡ä»¶å¤§å°: {(recordingState.audioData.size / 1024).toFixed(1)} KB
              </div>
            )}
          </div>

          {/* æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ */}
          <div className="bg-gray-50 dark:bg-gray-700 p-4 rounded-lg">
            <h3 className="text-lg font-semibold text-gray-900 dark:text-white mb-4">
              æ–‡ä»¶ä¸Šä¼ åˆ†æ
            </h3>

            <div className="space-y-4">
              <div>
                <label className="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-2">
                  é€‰æ‹©éŸ³é¢‘æ–‡ä»¶
                </label>
                <input
                  type="file"
                  accept="audio/*"
                  onChange={handleFileUpload}
                  className="block w-full text-sm text-gray-500 dark:text-gray-400
                    file:mr-4 file:py-2 file:px-4
                    file:rounded-lg file:border-0
                    file:text-sm file:font-medium
                    file:bg-blue-50 file:text-blue-700
                    dark:file:bg-blue-900 dark:file:text-blue-300
                    hover:file:bg-blue-100 dark:hover:file:bg-blue-800"
                />
              </div>

              {uploadedFile && (
                <div className="flex items-center justify-between">
                  <div className="text-sm text-gray-600 dark:text-gray-300">
                    {uploadedFile.name} ({(uploadedFile.size / 1024).toFixed(1)} KB)
                  </div>
                  <button
                    onClick={analyzeUploadedFile}
                    className="flex items-center space-x-2 px-4 py-2 bg-green-600 hover:bg-green-700 text-white rounded-lg font-medium text-sm"
                    disabled={isProcessing}
                  >
                    <Play className="w-4 h-4" />
                    <span>{isProcessing ? 'åˆ†æä¸­...' : 'åˆ†ææ–‡ä»¶'}</span>
                  </button>
                </div>
              )}
            </div>
          </div>

          {/* é”™è¯¯æç¤º */}
          {connectionError && (
            <div className="bg-red-100 dark:bg-red-900 border border-red-400 text-red-700 dark:text-red-200 px-4 py-3 rounded">
              <div className="flex items-center">
                <AlertCircle className="w-5 h-5 mr-2" />
                <span>{connectionError}</span>
              </div>
            </div>
          )}
        </div>

        {/* æƒ…ç»ªåˆ†æç»“æœ */}
        <div className="space-y-4">
          <h3 className="text-lg font-semibold text-gray-900 dark:text-white">
            è¯­éŸ³æƒ…ç»ªåˆ†æç»“æœ
          </h3>

          {recordingState.emotionResult ? (
            <div className="space-y-4">
              {/* ä¸»è¦æƒ…ç»ª */}
              <div className="bg-gradient-to-r from-purple-50 to-pink-50 dark:from-purple-900/20 dark:to-pink-900/20 p-4 rounded-lg">
                <div className="flex items-center justify-between">
                  <span className="text-sm font-medium text-gray-600 dark:text-gray-300">
                    ä¸»è¦æƒ…ç»ª
                  </span>
                  <span className={`text-lg font-bold ${getEmotionColor(getPrimaryEmotion(recordingState.emotionResult))}`}>
                    {getEmotionLabel(getPrimaryEmotion(recordingState.emotionResult))}
                  </span>
                </div>
                <div className="mt-2 text-2xl font-bold text-gray-900 dark:text-white">
                  {Math.round((recordingState.emotionResult as any)[getPrimaryEmotion(recordingState.emotionResult)] * 100)}%
                </div>
              </div>

              {/* æƒ…ç»ªåˆ†å¸ƒ */}
              <div className="space-y-2">
                {Object.entries(recordingState.emotionResult)
                  .filter(([key]) => key !== 'timestamp')
                  .map(([emotion, value]) => (
                    <div key={emotion} className="flex items-center justify-between">
                      <span className="text-sm text-gray-600 dark:text-gray-300 capitalize">
                        {getEmotionLabel(emotion)}
                      </span>
                      <div className="flex items-center space-x-2">
                        <div className="w-24 bg-gray-200 dark:bg-gray-700 rounded-full h-2">
                          <div
                            className="bg-purple-600 h-2 rounded-full transition-all duration-300"
                            style={{ width: `${value * 100}%` }}
                          />
                        </div>
                        <span className="text-sm font-medium text-gray-900 dark:text-white w-10 text-right">
                          {Math.round(value * 100)}%
                        </span>
                      </div>
                    </div>
                  ))}
              </div>

              {/* æ—¶é—´æˆ³ */}
              <div className="text-xs text-gray-500 dark:text-gray-400 pt-2 border-t border-gray-200 dark:border-gray-700">
                åˆ†ææ—¶é—´: {recordingState.emotionResult.timestamp.toLocaleTimeString()}
              </div>
            </div>
          ) : (
            <div className="bg-gray-50 dark:bg-gray-700 p-8 rounded-lg text-center">
              <Mic className="w-12 h-12 mx-auto mb-4 text-gray-400" />
              <p className="text-gray-600 dark:text-gray-300">
                å½•éŸ³æˆ–ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶åå°†æ˜¾ç¤ºåˆ†æç»“æœ
              </p>
            </div>
          )}
        </div>
      </div>

      {/* ä½¿ç”¨è¯´æ˜ */}
      <div className="mt-6 bg-purple-50 dark:bg-purple-900/20 border border-purple-200 dark:border-purple-800 rounded-lg p-4">
        <h4 className="font-medium text-purple-900 dark:text-purple-100 mb-2">
          ä½¿ç”¨æç¤º
        </h4>
        <ul className="text-sm text-purple-800 dark:text-purple-200 space-y-1">
          <li>â€¢ ç‚¹å‡»"å¼€å§‹å½•éŸ³"å¼€å§‹å®æ—¶è¯­éŸ³åˆ†æ</li>
          <li>â€¢ æˆ–è€…ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶è¿›è¡Œåˆ†æ</li>
          <li>â€¢ æ”¯æŒçš„æ ¼å¼: WAV, MP3</li>
          <li>â€¢ æ–‡ä»¶å¤§å°é™åˆ¶: 50MB</li>
          <li>â€¢ æ”¯æŒçš„æƒ…ç»ª: å¼€å¿ƒã€æ‚²ä¼¤ã€æ„¤æ€’ã€æƒŠè®¶ã€å¹³é™ã€åŒæ¶ã€ææƒ§</li>
        </ul>
      </div>
    </div>
  )
}

export default SpeechEmotionDetector
