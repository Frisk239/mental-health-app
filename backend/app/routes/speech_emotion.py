"""
è¯­éŸ³æƒ…ç»ªè¯†åˆ«è·¯ç”±
æ”¯æŒå®æ—¶éº¦å…‹é£å½•éŸ³å’ŒéŸ³é¢‘æ–‡ä»¶ä¸Šä¼ 
"""

from fastapi import APIRouter, UploadFile, File, HTTPException, WebSocket, WebSocketDisconnect
import json
import logging
import asyncio
from typing import Dict, List
import io
from app.services.speech_emotion_recognition import speech_emotion_service

router = APIRouter()

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# å­˜å‚¨æ´»è·ƒçš„WebSocketè¿æ¥
active_connections: Dict[str, WebSocket] = {}

@router.websocket("/ws/speech-emotion")
async def speech_emotion_websocket(websocket: WebSocket):
    """
    è¯­éŸ³æƒ…ç»ªè¯†åˆ«WebSocketç«¯ç‚¹
    æ¥æ”¶å®æ—¶éŸ³é¢‘æµï¼Œè¿”å›æƒ…ç»ªè¯†åˆ«ç»“æœ
    """
    client_id = f"speech_client_{id(websocket)}"
    await websocket.accept()

    # æ·»åŠ åˆ°æ´»è·ƒè¿æ¥
    active_connections[client_id] = websocket
    logger.info(f"ğŸ¤ è¯­éŸ³æƒ…ç»ªè¯†åˆ«å®¢æˆ·ç«¯è¿æ¥: {client_id} (æ´»è·ƒè¿æ¥æ•°: {len(active_connections)})")

    try:
        # åˆå§‹åŒ–è¯­éŸ³æƒ…ç»ªè¯†åˆ«æœåŠ¡
        if not speech_emotion_service.is_initialized:
            logger.info("ğŸ”§ åˆå§‹åŒ–è¯­éŸ³æƒ…ç»ªè¯†åˆ«æœåŠ¡...")
            success = await speech_emotion_service.initialize()
            if not success:
                await websocket.send_json({
                    "error": "è¯­éŸ³æƒ…ç»ªè¯†åˆ«æœåŠ¡åˆå§‹åŒ–å¤±è´¥",
                    "type": "init_failed"
                })
                return

        # éŸ³é¢‘æ•°æ®ç¼“å†²åŒº
        audio_buffer = bytearray()
        sample_rate = 16000  # Whisperé»˜è®¤é‡‡æ ·ç‡

        while True:
            try:
                # æ¥æ”¶å‰ç«¯å‘é€çš„éŸ³é¢‘æ•°æ®
                audio_data = await asyncio.wait_for(websocket.receive_bytes(), timeout=10.0)

                logger.debug(f"ğŸµ æ¥æ”¶åˆ°éŸ³é¢‘æ•°æ®ï¼Œå¤§å°: {len(audio_data)} bytes")

                # ç´¯ç§¯éŸ³é¢‘æ•°æ®
                audio_buffer.extend(audio_data)

                # å½“ç¼“å†²åŒºè¾¾åˆ°ä¸€å®šå¤§å°æˆ–æ”¶åˆ°ç‰¹æ®Šæ ‡è®°æ—¶è¿›è¡Œå¤„ç†
                # è¿™é‡Œç®€åŒ–å¤„ç†ï¼šæ¯æ”¶åˆ°æ•°æ®å°±ç«‹å³å¤„ç†
                if len(audio_buffer) > 0:
                    try:
                        # å¤„ç†éŸ³é¢‘æ•°æ®
                        result = await speech_emotion_service.process_audio_data(
                            bytes(audio_buffer),
                            sample_rate
                        )

                        # å‘é€ç»“æœå›å‰ç«¯
                        await websocket.send_json(result)

                        logger.debug(f"ğŸ“¤ å‘é€è¯­éŸ³æƒ…ç»ªè¯†åˆ«ç»“æœ: {result.get('emotion_chinese', 'æœªçŸ¥')}")

                        # æ¸…ç©ºç¼“å†²åŒºï¼Œå‡†å¤‡ä¸‹ä¸€æ®µéŸ³é¢‘
                        audio_buffer.clear()

                    except Exception as e:
                        logger.error(f"âŒ å¤„ç†éŸ³é¢‘æ•°æ®æ—¶å‡ºé”™: {e}")
                        await websocket.send_json({
                            "error": f"å¤„ç†å¤±è´¥: {str(e)}",
                            "type": "process_error"
                        })

            except asyncio.TimeoutError:
                # å‘é€å¿ƒè·³åŒ…ä¿æŒè¿æ¥
                await websocket.send_json({
                    "type": "heartbeat",
                    "timestamp": asyncio.get_event_loop().time()
                })
                continue

            except json.JSONDecodeError as e:
                logger.error(f"âŒ JSONè§£æå¤±è´¥: {e}")
                await websocket.send_json({
                    "error": "æ•°æ®æ ¼å¼é”™è¯¯",
                    "type": "json_error"
                })

    except WebSocketDisconnect:
        logger.info(f"ğŸ”Œ è¯­éŸ³æƒ…ç»ªè¯†åˆ«å®¢æˆ·ç«¯æ–­å¼€è¿æ¥: {client_id}")
    except Exception as e:
        logger.error(f"âŒ WebSocketè¿æ¥å¼‚å¸¸: {e}")
    finally:
        # ä»æ´»è·ƒè¿æ¥ä¸­ç§»é™¤
        if client_id in active_connections:
            del active_connections[client_id]
        logger.info(f"ğŸ æ¸…ç†è¯­éŸ³è¿æ¥: {client_id} (å‰©ä½™è¿æ¥æ•°: {len(active_connections)})")

@router.post("/speech-emotion/upload")
async def upload_audio_file(file: UploadFile = File(...)):
    """
    ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶è¿›è¡Œæƒ…ç»ªè¯†åˆ«

    Args:
        file: ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶

    Returns:
        Dict: æƒ…ç»ªè¯†åˆ«ç»“æœ
    """
    try:
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        allowed_types = ["audio/wav", "audio/mpeg", "audio/mp3", "audio/x-wav", "audio/wave"]
        if file.content_type not in allowed_types:
            raise HTTPException(
                status_code=400,
                detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file.content_type}ã€‚æ”¯æŒçš„ç±»å‹: WAV, MP3"
            )

        # æ£€æŸ¥æ–‡ä»¶å¤§å° (é™åˆ¶ä¸º50MB)
        file_size = 0
        content = await file.read()
        file_size = len(content)

        if file_size > 50 * 1024 * 1024:  # 50MB
            raise HTTPException(
                status_code=400,
                detail="æ–‡ä»¶è¿‡å¤§ï¼Œè¯·ä¸Šä¼ å°äº50MBçš„éŸ³é¢‘æ–‡ä»¶"
            )

        logger.info(f"ğŸ“ æ¥æ”¶åˆ°éŸ³é¢‘æ–‡ä»¶: {file.filename}, å¤§å°: {file_size} bytes, ç±»å‹: {file.content_type}")

        # åˆå§‹åŒ–æœåŠ¡ï¼ˆå¦‚æœæœªåˆå§‹åŒ–ï¼‰
        if not speech_emotion_service.is_initialized:
            logger.info("ğŸ”§ åˆå§‹åŒ–è¯­éŸ³æƒ…ç»ªè¯†åˆ«æœåŠ¡...")
            success = await speech_emotion_service.initialize()
            if not success:
                raise HTTPException(
                    status_code=500,
                    detail="è¯­éŸ³æƒ…ç»ªè¯†åˆ«æœåŠ¡åˆå§‹åŒ–å¤±è´¥"
                )

        # å¤„ç†éŸ³é¢‘æ–‡ä»¶
        result = await speech_emotion_service.process_audio_data(content)

        logger.info(f"âœ… éŸ³é¢‘æ–‡ä»¶å¤„ç†å®Œæˆ: {file.filename} -> {result.get('emotion_chinese', 'æœªçŸ¥')}")

        return {
            "success": True,
            "result": result,
            "file_info": {
                "filename": file.filename,
                "size": file_size,
                "content_type": file.content_type
            }
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ å¤„ç†ä¸Šä¼ æ–‡ä»¶å¤±è´¥: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"å¤„ç†æ–‡ä»¶å¤±è´¥: {str(e)}"
        )

@router.get("/speech-emotion/status")
async def get_speech_emotion_service_status():
    """
    è·å–è¯­éŸ³æƒ…ç»ªè¯†åˆ«æœåŠ¡çŠ¶æ€
    """
    return {
        "is_initialized": speech_emotion_service.is_initialized,
        "model_info": speech_emotion_service.get_model_info(),
        "active_connections": len(active_connections),
        "supported_emotions": list(speech_emotion_service.emotion_labels_chinese.values())
    }

@router.post("/speech-emotion/test")
async def test_speech_emotion():
    """
    æµ‹è¯•è¯­éŸ³æƒ…ç»ªè¯†åˆ«åŠŸèƒ½ï¼ˆä½¿ç”¨ç©ºéŸ³é¢‘ï¼‰
    """
    try:
        # åˆå§‹åŒ–æœåŠ¡ï¼ˆå¦‚æœæœªåˆå§‹åŒ–ï¼‰
        if not speech_emotion_service.is_initialized:
            logger.info("ğŸ”§ åˆå§‹åŒ–è¯­éŸ³æƒ…ç»ªè¯†åˆ«æœåŠ¡...")
            success = await speech_emotion_service.initialize()
            if not success:
                return {
                    "success": False,
                    "error": "è¯­éŸ³æƒ…ç»ªè¯†åˆ«æœåŠ¡åˆå§‹åŒ–å¤±è´¥",
                    "message": "æœåŠ¡åˆå§‹åŒ–å¤±è´¥"
                }

        # åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•éŸ³é¢‘ï¼ˆé™éŸ³ï¼‰
        sample_rate = 16000
        duration = 1.0  # 1ç§’
        silent_audio = np.zeros(int(sample_rate * duration), dtype=np.float32)

        # è½¬æ¢ä¸ºå­—èŠ‚æ•°æ®
        audio_buffer = io.BytesIO()
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥ä½¿ç”¨é€‚å½“çš„éŸ³é¢‘ç¼–ç 
        # ä¸ºäº†æµ‹è¯•ï¼Œæˆ‘ä»¬ç›´æ¥ä¼ é€’numpyæ•°ç»„çš„å­—èŠ‚è¡¨ç¤º
        audio_bytes = silent_audio.tobytes()

        # å¤„ç†æµ‹è¯•éŸ³é¢‘
        result = await speech_emotion_service.process_audio_data(audio_bytes, sample_rate)

        return {
            "success": True,
            "result": result,
            "message": "è¯­éŸ³æƒ…ç»ªè¯†åˆ«æµ‹è¯•æˆåŠŸ"
        }

    except Exception as e:
        logger.error(f"âŒ è¯­éŸ³æƒ…ç»ªè¯†åˆ«æµ‹è¯•å¤±è´¥: {e}")
        return {
            "success": False,
            "error": str(e),
            "message": "è¯­éŸ³æƒ…ç»ªè¯†åˆ«æµ‹è¯•å¤±è´¥"
        }
