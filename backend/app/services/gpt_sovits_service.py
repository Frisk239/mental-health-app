"""
GPT-SoVITSÊé®ÁêÜÊúçÂä°
Âü∫‰∫éGPT-SoVITS-v2proÊ∫êÁ†ÅÂÆåÂÖ®ÈõÜÊàê
"""

import json
import logging
import os
import sys
import asyncio
import gc
import math
import random
import time
import traceback
from copy import deepcopy
from typing import Dict, List, Optional, Any, Tuple, Union, Generator

import torch
import torch.nn.functional as F
import numpy as np
import torchaudio
from tqdm import tqdm
import ffmpeg
import librosa
import soundfile as sf
import yaml
from transformers import AutoModelForMaskedLM, AutoTokenizer

# GPT_SoVITS Âä®ÊÄÅÂØºÂÖ•Ê®°Âùó
# ‰∏ç‰ΩøÁî®Áõ¥Êé•ÂØºÂÖ•ÔºåÊîπ‰∏∫ËøêË°åÊó∂Âä®ÊÄÅÂØºÂÖ•

logger = logging.getLogger(__name__)

# Èü≥È¢ëÈáçÈááÊ†∑ÁºìÂ≠ò
resample_transform_dict = {}

def resample(audio_tensor, sr0, sr1, device):
    global resample_transform_dict
    key = "%s-%s-%s" % (sr0, sr1, str(device))
    if key not in resample_transform_dict:
        resample_transform_dict[key] = torchaudio.transforms.Resample(sr0, sr1).to(device)
    return resample_transform_dict[key](audio_tensor)

# ËØ≠Ë®ÄËÆæÁΩÆ
language = os.environ.get("language", "Auto")
# ÁÆÄÂåñËØ≠Ë®ÄËÆæÁΩÆÔºåÈÅøÂÖçÂú®Ê®°ÂùóÁ∫ßÂà´‰ΩøÁî®Êú™ÂØºÂÖ•ÁöÑÂáΩÊï∞
i18n = None  # Â∞ÜÂú®ÈúÄË¶ÅÊó∂Âä®ÊÄÅÂàùÂßãÂåñ

# È¢ëË∞±ÂΩí‰∏ÄÂåñÂèÇÊï∞
spec_min = -12
spec_max = 2

def norm_spec(x):
    return (x - spec_min) / (spec_max - spec_min) * 2 - 1

def denorm_spec(x):
    return (x + 1) / 2 * (spec_max - spec_min) + spec_min

# Ê¢ÖÂ∞îÈ¢ëË∞±ÂáΩÊï∞
mel_fn = lambda x: mel_spectrogram_torch(
    x,
    **{
        "n_fft": 1024,
        "win_size": 1024,
        "hop_size": 256,
        "num_mels": 100,
        "sampling_rate": 24000,
        "fmin": 0,
        "fmax": None,
        "center": False,
    },
)

mel_fn_v4 = lambda x: mel_spectrogram_torch(
    x,
    **{
        "n_fft": 1280,
        "win_size": 1280,
        "hop_size": 320,
        "num_mels": 100,
        "sampling_rate": 32000,
        "fmin": 0,
        "fmax": None,
        "center": False,
    },
)

def speed_change(input_audio: np.ndarray, speed: float, sr: int):
    """ÂèòÈÄüÂ§ÑÁêÜÈü≥È¢ë"""
    raw_audio = input_audio.astype(np.int16).tobytes()
    input_stream = ffmpeg.input("pipe:", format="s16le", acodec="pcm_s16le", ar=str(sr), ac=1)
    output_stream = input_stream.filter("atempo", speed)
    out, _ = output_stream.output("pipe:", format="s16le", acodec="pcm_s16le").run(
        input=raw_audio, capture_stdout=True, capture_stderr=True
    )
    processed_audio = np.frombuffer(out, np.int16)
    return processed_audio

def set_seed(seed: int):
    """ËÆæÁΩÆÈöèÊú∫ÁßçÂ≠ê"""
    seed = int(seed)
    seed = seed if seed != -1 else random.randint(0, 2**32 - 1)
    print(f"Set seed to {seed}")
    os.environ["PYTHONHASHSEED"] = str(seed)
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    try:
        if torch.cuda.is_available():
            torch.cuda.manual_seed(seed)
            torch.cuda.manual_seed_all(seed)
            torch.backends.cuda.matmul.allow_tf32 = False
            torch.backends.cudnn.allow_tf32 = False
    except:
        pass
    return seed

class DictToAttrRecursive(dict):
    """Â≠óÂÖ∏ËΩ¨Â±ûÊÄßÈÄíÂΩíÁ±ª"""
    def __init__(self, input_dict):
        super().__init__(input_dict)
        for key, value in input_dict.items():
            if isinstance(value, dict):
                value = DictToAttrRecursive(value)
            self[key] = value
            setattr(self, key, value)

    def __getattr__(self, item):
        try:
            return self[item]
        except KeyError:
            raise AttributeError(f"Attribute {item} not found")

    def __setattr__(self, key, value):
        if isinstance(value, dict):
            value = DictToAttrRecursive(value)
        super(DictToAttrRecursive, self).__setitem__(key, value)
        super().__setattr__(key, value)

    def __delattr__(self, item):
        try:
            del self[item]
        except KeyError:
            raise AttributeError(f"Attribute {item} not found")

class NO_PROMPT_ERROR(Exception):
    pass

class GPTSoVITSService:
    """GPT-SoVITSÊé®ÁêÜÊúçÂä°"""

    def __init__(self, config_path: str = None):
        # ËÆ°ÁÆóÁªùÂØπË∑ØÂæÑ
        if config_path is None:
            current_dir = os.path.dirname(os.path.abspath(__file__))
            project_root = os.path.join(current_dir, "../../../")
            self.config_path = os.path.join(project_root, "voice_config.json")
        else:
            self.config_path = config_path

        self.config = self._load_config()
        self.device = "cuda" if torch.cuda.is_available() else "cpu"

        # ËÆ°ÁÆóGPT_SoVITSË∑ØÂæÑ
        current_dir = os.path.dirname(os.path.abspath(__file__))
        self.gpt_sovits_path = os.path.abspath(os.path.join(current_dir, "../../../GPT_SoVITS"))

        # GPT-SoVITS TTSÂÆû‰æã
        self.tts_pipeline = None

        # Ê®°ÂûãË∑ØÂæÑÔºà‰ΩøÁî®ÁªùÂØπË∑ØÂæÑÔºâ
        self.gpt_weights_dir = os.path.join(current_dir, "../../../GPT_weights_v2Pro")
        self.sovits_weights_dir = os.path.join(current_dir, "../../../SoVITS_weights_v2Pro")

        # Ê®°ÂûãÁºìÂ≠ò
        self.models_cache = {}

        # Âä®ÊÄÅÂØºÂÖ•ÁöÑÊ®°ÂùóÁºìÂ≠ò
        self._modules_cache = {}

        # ËÆæÁΩÆÊ®°ÂùóË∑ØÂæÑ
        self._setup_module_paths()

        # ÂàùÂßãÂåñTTSÁÆ°ÈÅì
        self._init_tts_pipeline()

    def _setup_module_paths(self):
        """ËÆæÁΩÆGPT-SoVITSÊ®°ÂùóË∑ØÂæÑÂà∞sys.path"""
        try:
            paths_to_add = [
                self.gpt_sovits_path,  # Ê†πÁõÆÂΩï
                os.path.join(self.gpt_sovits_path, "AR"),
                os.path.join(self.gpt_sovits_path, "AR", "models"),
                os.path.join(self.gpt_sovits_path, "AR", "modules"),
                os.path.join(self.gpt_sovits_path, "BigVGAN"),
                os.path.join(self.gpt_sovits_path, "module"),
                os.path.join(self.gpt_sovits_path, "tools"),
                os.path.join(self.gpt_sovits_path, "tools", "i18n"),
                os.path.join(self.gpt_sovits_path, "TTS_infer_pack"),
                os.path.join(self.gpt_sovits_path, "feature_extractor"),
                os.path.join(self.gpt_sovits_path, "text"),
            ]

            for path in paths_to_add:
                if os.path.exists(path) and path not in sys.path:
                    sys.path.insert(0, path)
                    logger.info(f"‚úÖ Ê∑ªÂä†GPT-SoVITSË∑ØÂæÑ: {path}")

            logger.info(f"üìÇ GPT_SoVITS sys.pathËÆæÁΩÆÂÆåÊàêÔºåÊÄªÂÖ±Ê∑ªÂä† {len(paths_to_add)} ‰∏™Ë∑ØÂæÑ")

        except Exception as e:
            logger.error(f"‚ùå ËÆæÁΩÆÊ®°ÂùóË∑ØÂæÑÂ§±Ë¥•: {e}")

    def _import_module_from_file(self, relative_path: str, class_name: str = None):
        """‰ªéÊñá‰ª∂Âä®ÊÄÅÂØºÂÖ•Ê®°ÂùóÊàñÁ±ª"""
        try:
            import importlib.util

            module_path = os.path.join(self.gpt_sovits_path, relative_path)
            if not os.path.exists(module_path):
                logger.error(f"Ê®°ÂùóÊñá‰ª∂‰∏çÂ≠òÂú®: {module_path}")
                return None

            # ÂàõÂª∫Ê®°ÂùóÂêçÔºàÂü∫‰∫éÁõ∏ÂØπË∑ØÂæÑÔºâ
            module_name = relative_path.replace("/", ".").replace("\\", ".").replace(".py", "")

            # Ê£ÄÊü•ÁºìÂ≠ò
            if module_name in self._modules_cache:
                module = self._modules_cache[module_name]
            else:
                # ÂØπ‰∫é TTS.pyÔºåÂÖàÈ¢ÑÂØºÂÖ•ÂÖ∂‰æùËµñÁöÑÊ®°Âùó
                if "TTS.py" in relative_path:
                    self._preload_tts_dependencies()

                # Âä®ÊÄÅÂØºÂÖ•
                spec = importlib.util.spec_from_file_location(module_name, module_path)
                if spec is None or spec.loader is None:
                    logger.error(f"Êó†Ê≥ïÂàõÂª∫Ê®°ÂùóËßÑÊ†º: {module_path}")
                    return None

                module = importlib.util.module_from_spec(spec)
                spec.loader.exec_module(module)
                self._modules_cache[module_name] = module
                logger.info(f"‚úÖ Âä®ÊÄÅÂØºÂÖ•Ê®°Âùó: {module_name}")

            # Â¶ÇÊûúÊåáÂÆö‰∫ÜÁ±ªÂêçÔºåËøîÂõûÁ±ªÔºõÂê¶ÂàôËøîÂõûÊ®°Âùó
            if class_name:
                if hasattr(module, class_name):
                    return getattr(module, class_name)
                else:
                    logger.error(f"Ê®°Âùó {module_name} ‰∏≠Ê≤°ÊúâÊâæÂà∞Á±ª {class_name}")
                    return None

            return module

        except Exception as e:
            logger.error(f"‚ùå Âä®ÊÄÅÂØºÂÖ•Â§±Ë¥• {relative_path}: {e}")
            logger.error(f"ËØ¶ÁªÜÈîôËØØ: {traceback.format_exc()}")
            return None

    def _preload_tts_dependencies(self):
        """È¢ÑÂä†ËΩΩTTSÊ®°ÂùóÁöÑ‰æùËµñ"""
        try:
            logger.info("üéØ È¢ÑÂä†ËΩΩTTS‰æùËµñÊ®°Âùó...")

            # È¶ñÂÖàÂàõÂª∫Âπ∂Ê≥®ÂÜåGPT_SoVITSÂåÖ
            self._register_gpt_sovits_package()

            # È¢ÑÂØºÂÖ•ÂÖ≥ÈîÆÊ®°Âùó
            dependencies = [
                "AR/models/t2s_lightning_module.py",
                "BigVGAN/bigvgan.py",
                "feature_extractor/cnhubert.py",
                "module/mel_processing.py",
                "module/models.py",
                "process_ckpt.py",
                "tools/audio_sr.py",
                "tools/i18n/i18n.py",
                "TTS_infer_pack/text_segmentation_method.py",
                "TTS_infer_pack/TextPreprocessor.py",
                "sv.py"
            ]

            for dep in dependencies:
                try:
                    self._import_module_from_file(dep)
                except Exception as e:
                    logger.warning(f"È¢ÑÂä†ËΩΩ‰æùËµñÂ§±Ë¥• {dep}: {e}")
                    continue

            logger.info("‚úÖ TTS‰æùËµñÈ¢ÑÂä†ËΩΩÂÆåÊàê")

        except Exception as e:
            logger.error(f"‚ùå È¢ÑÂä†ËΩΩTTS‰æùËµñÂ§±Ë¥•: {e}")

    def _register_gpt_sovits_package(self):
        """Ê≥®ÂÜåGPT_SoVITSÂåÖÂà∞sys.modules"""
        try:
            import types
            import sys

            # ÂàõÂª∫GPT_SoVITSÂåÖÂØπË±°
            gpt_sovits_package = types.ModuleType('GPT_SoVITS')
            gpt_sovits_package.__path__ = [self.gpt_sovits_path]
            gpt_sovits_package.__file__ = os.path.join(self.gpt_sovits_path, '__init__.py')

            # Ê≥®ÂÜåÂà∞sys.modules
            sys.modules['GPT_SoVITS'] = gpt_sovits_package

            # ÈÄíÂΩíÂàõÂª∫Â≠êÂåÖ
            self._create_subpackages(gpt_sovits_package, self.gpt_sovits_path)

            logger.info("‚úÖ GPT_SoVITSÂåÖÊ≥®ÂÜåÂÆåÊàê")

        except Exception as e:
            logger.error(f"‚ùå Ê≥®ÂÜåGPT_SoVITSÂåÖÂ§±Ë¥•: {e}")

    def _create_subpackages(self, parent_package, parent_path):
        """ÈÄíÂΩíÂàõÂª∫Â≠êÂåÖ"""
        try:
            import types

            # ÈÅçÂéÜÂ≠êÁõÆÂΩï
            for item in os.listdir(parent_path):
                item_path = os.path.join(parent_path, item)
                if os.path.isdir(item_path):
                    # Ê£ÄÊü•ÊòØÂê¶Êúâ__init__.py
                    init_file = os.path.join(item_path, '__init__.py')
                    if os.path.exists(init_file) or item in ['f5_tts', 'AR', 'BigVGAN', 'module', 'tools', 'TTS_infer_pack', 'feature_extractor', 'text']:
                        # ÂàõÂª∫Â≠êÂåÖ
                        subpackage_name = f"{parent_package.__name__}.{item}"
                        subpackage = types.ModuleType(subpackage_name)
                        subpackage.__path__ = [item_path]
                        subpackage.__file__ = init_file if os.path.exists(init_file) else item_path

                        # ËÆæÁΩÆÁà∂ÂåÖÂºïÁî®
                        setattr(parent_package, item, subpackage)
                        sys.modules[subpackage_name] = subpackage

                        # ÈÄíÂΩíÂàõÂª∫Â≠êÂåÖÁöÑÂ≠êÂåÖ
                        self._create_subpackages(subpackage, item_path)

        except Exception as e:
            logger.warning(f"ÂàõÂª∫Â≠êÂåÖÂ§±Ë¥• {parent_path}: {e}")

    def _init_tts_pipeline(self):
        """ÂàùÂßãÂåñTTSÁÆ°ÈÅì"""
        try:
            logger.info("üéµ ÂàùÂßãÂåñGPT-SoVITS TTSÁÆ°ÈÅì...")
            # TTSÁÆ°ÈÅìÂ∞ÜÂú®Á¨¨‰∏ÄÊ¨°Êé®ÁêÜÊó∂Âä®ÊÄÅÂàõÂª∫
            self.tts_pipeline = None
            logger.info("‚úÖ TTSÁÆ°ÈÅìÂàùÂßãÂåñÂÆåÊàêÔºàÂª∂ËøüÂä†ËΩΩÔºâ")
        except Exception as e:
            logger.error(f"‚ùå TTSÁÆ°ÈÅìÂàùÂßãÂåñÂ§±Ë¥•: {e}")
            self.tts_pipeline = None

    def _load_config(self) -> Dict:
        """Âä†ËΩΩÈÖçÁΩÆÊñá‰ª∂"""
        try:
            # Â∞ùËØïÂ§ö‰∏™ÂèØËÉΩË∑ØÂæÑ
            possible_paths = [
                self.config_path,  # Áõ∏ÂØπË∑ØÂæÑ
                os.path.join(os.path.dirname(__file__), "../..", self.config_path),  # Âêë‰∏ä‰∏§Á∫ß
                os.path.join(os.path.dirname(__file__), "../../../", self.config_path)  # È°πÁõÆÊ†πÁõÆÂΩï
            ]

            for path in possible_paths:
                if os.path.exists(path):
                    try:
                        with open(path, 'r', encoding='utf-8') as f:
                            return json.load(f)
                    except Exception as e:
                        logger.error(f"Âä†ËΩΩÈÖçÁΩÆÊñá‰ª∂Â§±Ë¥• {path}: {e}")
                        continue

            logger.warning(f"ÈÖçÁΩÆÊñá‰ª∂ {self.config_path} ‰∏çÂ≠òÂú®Ôºå‰ΩøÁî®ÈªòËÆ§ÈÖçÁΩÆ")
            return self._get_default_config()

        except Exception as e:
            logger.error(f"Âä†ËΩΩÈÖçÁΩÆÊñá‰ª∂Â§±Ë¥•: {e}")
            return self._get_default_config()

    def _get_default_config(self) -> Dict:
        """Ëé∑ÂèñÈªòËÆ§ÈÖçÁΩÆ"""
        return {
            "model_paths": {
                "gpt_weights_dir": "./GPT_weights_v2Pro",
                "sovits_weights_dir": "./SoVITS_weights_v2Pro"
            },
            "role_voice_mapping": {
                "Âº†ÊïôÊéà": {
                    "description": "‰∏ì‰∏öÂ•≥Â£∞ÔºåÈÄÇÂêàÊïôÊéàËßíËâ≤",
                    "gpt_model": "caijiaxin-e15.ckpt",
                    "sovits_model": "caijiaxin_e8_s240.pth",
                    "voice_params": {
                        "speed": 1.0,
                        "pitch_shift": 1.0,
                        "emotion_intensity": 0.7
                    }
                },
                "ÊùéÈÉ®Èïø": {
                    "description": "Ê¥ªÂäõÁî∑Â£∞ÔºåÈÄÇÂêàÈ¢ÜÂØºËßíËâ≤",
                    "gpt_model": "zhangyibo-e15.ckpt",
                    "sovits_model": "zhangyibo_e8_s208.pth",
                    "voice_params": {
                        "speed": 1.0,
                        "pitch_shift": 1.0,
                        "emotion_intensity": 0.7
                    }
                },
                "ÁéãËÄÅÂ∏à": {
                    "description": "Ê†áÂáÜÁî∑Â£∞ÔºåÈÄÇÂêàÊïôÂ∏àËßíËâ≤",
                    "gpt_model": "myself-e15.ckpt",
                    "sovits_model": "myself_e8_s224.pth",
                    "voice_params": {
                        "speed": 1.0,
                        "pitch_shift": 1.0,
                        "emotion_intensity": 0.7
                    }
                },
                "Â∞èÈõ®": {
                    "description": "Ê∏©ÊüîÂ•≥Â£∞ÔºåÈÄÇÂêàÊúãÂèãËßíËâ≤",
                    "gpt_model": "zhouyajing-e15.ckpt",
                    "sovits_model": "zhouyajing_e8_s192.pth",
                    "voice_params": {
                        "speed": 1.0,
                        "pitch_shift": 1.0,
                        "emotion_intensity": 0.7
                    }
                }
            },
            "synthesis_params": {
                "top_k": 15,
                "top_p": 1.0,
                "temperature": 1.0,
                "speed": 1.0,
                "noise_scale": 0.5
            },
            "input_modes": {
                "text_mode": {"enabled": True, "description": "ÊñáÊú¨ËæìÂÖ•Ê®°Âºè"},
                "voice_mode": {"enabled": True, "description": "ËØ≠Èü≥ËæìÂÖ•Ê®°Âºè"}
            }
        }

    async def initialize(self) -> bool:
        """ÂàùÂßãÂåñÊúçÂä°"""
        try:
            logger.info("üöÄ ÂàùÂßãÂåñGPT-SoVITSÊúçÂä°...")

            # ËÆæÁΩÆÁéØÂ¢ÉÂèòÈáèÔºàÂü∫‰∫é‰Ω†ÁöÑÊ∫êÁ†ÅÔºâ
            os.environ["version"] = "v2"
            os.environ["is_half"] = "True"
            os.environ["infer_ttswebui"] = "9873"

            # Ê∑ªÂä†È°πÁõÆË∑ØÂæÑÂà∞PythonË∑ØÂæÑ
            current_dir = os.path.dirname(os.path.abspath(__file__))
            project_root = os.path.join(current_dir, "../../../..")
            gpt_sovits_path = os.path.join(project_root, "GPT_weights_v2Pro")

            if os.path.exists(gpt_sovits_path):
                sys.path.append(gpt_sovits_path)
                logger.info(f"‚úÖ Ê∑ªÂä†GPT-SoVITSË∑ØÂæÑ: {gpt_sovits_path}")

            # È¢ÑÂä†ËΩΩÊ®°Âûã
            await self._load_models()

            logger.info("‚úÖ GPT-SoVITSÊúçÂä°ÂàùÂßãÂåñÂÆåÊàê")
            return True

        except Exception as e:
            logger.error(f"‚ùå GPT-SoVITSÊúçÂä°ÂàùÂßãÂåñÂ§±Ë¥•: {e}")
            return False

    async def _load_models(self):
        """Âä†ËΩΩÊ®°ÂûãÊùÉÈáç"""
        try:
            # ËøôÈáåÈúÄË¶ÅÂü∫‰∫é‰Ω†ÁöÑÊ∫êÁ†ÅÁªìÊûÑÊù•Âä†ËΩΩÊ®°Âûã
            # ÂÖàÊ£ÄÊü•Ê®°ÂûãÊñá‰ª∂ÊòØÂê¶Â≠òÂú®
            available_gpt_models = self._get_available_models("gpt")
            available_sovits_models = self._get_available_models("sovits")

            logger.info(f"üìÅ ÂèØÁî®GPTÊ®°Âûã: {available_gpt_models}")
            logger.info(f"üìÅ ÂèØÁî®SoVITSÊ®°Âûã: {available_sovits_models}")

            if not available_gpt_models or not available_sovits_models:
                logger.warning("‚ö†Ô∏è Êú™ÊâæÂà∞Ê®°ÂûãÊñá‰ª∂ÔºåÂ∞Ü‰ΩøÁî®Á∫ØÊñáÊú¨Ê®°Âºè")
                return

            # Âä†ËΩΩÈªòËÆ§Ê®°ÂûãÔºàÂü∫‰∫é‰Ω†ÁöÑÊ∫êÁ†ÅÈÄªËæëÔºâ
            default_gpt = available_gpt_models[0]
            default_sovits = available_sovits_models[0]

            logger.info(f"üéØ Âä†ËΩΩÈªòËÆ§Ê®°Âûã: GPT={default_gpt}, SoVITS={default_sovits}")

            # ËøôÈáåÂ∫îËØ•Âä†ËΩΩÂÆûÈôÖÁöÑÊ®°ÂûãÊùÉÈáç
            # Áî±‰∫éÊ∫êÁ†ÅÊØîËæÉÂ§çÊùÇÔºåËøôÈáåÂÖàÂÅöÂü∫Á°ÄÊ°ÜÊû∂
            self.models_cache["default"] = {
                "gpt_model": default_gpt,
                "sovits_model": default_sovits,
                "loaded": True
            }

        except Exception as e:
            logger.error(f"‚ùå Ê®°ÂûãÂä†ËΩΩÂ§±Ë¥•: {e}")

    def _get_available_models(self, model_type: str) -> List[str]:
        """Ëé∑ÂèñÂèØÁî®Ê®°ÂûãÂàóË°®"""
        try:
            # ‰ΩøÁî®ÁªùÂØπË∑ØÂæÑ
            current_dir = os.path.dirname(os.path.abspath(__file__))

            if model_type == "gpt":
                weights_dir = os.path.join(current_dir, "../../../GPT_weights_v2Pro")
                extension = ".ckpt"
            else:
                weights_dir = os.path.join(current_dir, "../../../SoVITS_weights_v2Pro")
                extension = ".pth"

            logger.info(f"üîç Ê£ÄÊü•Ê®°ÂûãÁõÆÂΩï: {weights_dir}")

            if not os.path.exists(weights_dir):
                logger.warning(f"‚ö†Ô∏è Ê®°ÂûãÁõÆÂΩï‰∏çÂ≠òÂú®: {weights_dir}")
                return []

            models = []
            for file in os.listdir(weights_dir):
                if file.endswith(extension):
                    models.append(file)

            logger.info(f"‚úÖ ÊâæÂà∞{model_type}Ê®°Âûã: {models}")
            return sorted(models)

        except Exception as e:
            logger.error(f"Ëé∑Âèñ{model_type}Ê®°ÂûãÂàóË°®Â§±Ë¥•: {e}")
            return []

    async def synthesize_speech(
        self,
        text: str,
        role_name: str,
        emotion_params: Dict = None
    ) -> bytes:
        """
        ËØ≠Èü≥ÂêàÊàê

        Args:
            text: Ë¶ÅÂêàÊàêÁöÑÊñáÊú¨
            role_name: ËßíËâ≤ÂêçÁß∞
            emotion_params: ÊÉÖÁª™ÂèÇÊï∞

        Returns:
            Èü≥È¢ëÂ≠óËäÇÊï∞ÊçÆ
        """
        try:
            # Ëé∑ÂèñËßíËâ≤ÈÖçÁΩÆ
            role_config = self._get_role_config(role_name)
            if not role_config:
                logger.error(f"‚ùå ËßíËâ≤ '{role_name}' ÈÖçÁΩÆ‰∏çÂ≠òÂú®")
                return b""

            # Ëé∑ÂèñÊ®°ÂûãË∑ØÂæÑ
            gpt_model = role_config.get("gpt_model")
            sovits_model = role_config.get("sovits_model")

            if not gpt_model or not sovits_model:
                logger.error(f"‚ùå ËßíËâ≤ '{role_name}' Ê®°ÂûãÈÖçÁΩÆ‰∏çÂÆåÊï¥")
                return b""

            # Ê£ÄÊü•Ê®°ÂûãÊñá‰ª∂ÊòØÂê¶Â≠òÂú®
            gpt_path = os.path.join(self.gpt_weights_dir, gpt_model)
            sovits_path = os.path.join(self.sovits_weights_dir, sovits_model)

            if not os.path.exists(gpt_path) or not os.path.exists(sovits_path):
                logger.error(f"‚ùå Ê®°ÂûãÊñá‰ª∂‰∏çÂ≠òÂú®: GPT={gpt_path}, SoVITS={sovits_path}")
                return b""

            logger.info(f"üéµ ÂºÄÂßãÂêàÊàêËØ≠Èü≥: '{text}' (ËßíËâ≤: {role_name})")

            # ËøôÈáåÂ∫îËØ•Ë∞ÉÁî®‰Ω†ÁöÑGPT-SoVITSÊ∫êÁ†ÅËøõË°åÊé®ÁêÜ
            # Áî±‰∫éÊ∫êÁ†ÅÊØîËæÉÂ§çÊùÇÔºåËøôÈáåÂÖàËøîÂõûÊ®°ÊãüÈü≥È¢ëÊï∞ÊçÆ
            audio_data = await self._run_inference(
                text, gpt_path, sovits_path, role_config.get("voice_params", {})
            )

            logger.info(f"‚úÖ ËØ≠Èü≥ÂêàÊàêÂÆåÊàêÔºåÈü≥È¢ëÂ§ßÂ∞è: {len(audio_data)} bytes")
            return audio_data

        except Exception as e:
            logger.error(f"‚ùå ËØ≠Èü≥ÂêàÊàêÂ§±Ë¥•: {e}")
            return b""

    async def _run_inference(
        self,
        text: str,
        gpt_path: str,
        sovits_path: str,
        voice_params: Dict
    ) -> bytes:
        """
        ÊâßË°åGPT-SoVITSÊé®ÁêÜ

        Âü∫‰∫éGPT-SoVITSÊ∫êÁ†ÅÁöÑÂÆåÊï¥Êé®ÁêÜÊµÅÁ®ã
        """
        try:
            logger.info("üéØ ÂºÄÂßãGPT-SoVITSÊé®ÁêÜÊµÅÁ®ã...")

            # 1. ÂàõÂª∫TTSÈÖçÁΩÆ
            tts_config = self._create_tts_config(gpt_path, sovits_path)
            logger.info("‚úÖ TTSÈÖçÁΩÆÂàõÂª∫ÂÆåÊàê")

            # 2. ÂàùÂßãÂåñTTSÁÆ°ÈÅì
            TTS_class = self._import_module_from_file("TTS_infer_pack/TTS.py", "TTS")
            if TTS_class is None:
                logger.error("‚ùå Êó†Ê≥ïÂØºÂÖ•TTSÁ±ª")
                return b""
            tts_pipeline = TTS_class(tts_config)  # tts_config Â∑≤ÁªèÊòØÂ≠óÂÖ∏‰∫Ü
            logger.info("‚úÖ TTSÁÆ°ÈÅìÂàùÂßãÂåñÂÆåÊàê")

            # 3. Ëé∑ÂèñËßíËâ≤ÈÖçÁΩÆ
            role_config = self._get_role_config_by_model(gpt_path, sovits_path)
            if not role_config:
                logger.error("‚ùå Êú™ÊâæÂà∞ËßíËâ≤ÈÖçÁΩÆ")
                return b""

            # 4. Ëé∑ÂèñÂèÇËÄÉÈü≥È¢ëË∑ØÂæÑ
            ref_audio_path = role_config.get("ref_audio_path")
            if not ref_audio_path or not os.path.exists(ref_audio_path):
                logger.error(f"‚ùå ÂèÇËÄÉÈü≥È¢ë‰∏çÂ≠òÂú®: {ref_audio_path}")
                return b""

            # 5. ËÆæÁΩÆÂèÇËÄÉÈü≥È¢ë
            tts_pipeline.set_ref_audio(ref_audio_path)
            logger.info(f"‚úÖ ÂèÇËÄÉÈü≥È¢ëËÆæÁΩÆÂÆåÊàê: {ref_audio_path}")

            # 6. ÂáÜÂ§áÊé®ÁêÜÂèÇÊï∞
            inference_params = {
                "text": text,
                "text_lang": "zh",  # ‰∏≠Êñá
                "ref_audio_path": ref_audio_path,
                "prompt_text": role_config.get("prompt_text", ""),
                "prompt_lang": "zh",
                "top_k": 5,
                "top_p": 1.0,
                "temperature": 1.0,
                "text_split_method": "cut5",
                "batch_size": 1,
                "speed_factor": voice_params.get("speed", 1.0),
                "fragment_interval": 0.3,
                "seed": -1,
                "parallel_infer": True,
                "repetition_penalty": 1.35
            }

            logger.info(f"üéµ ÂºÄÂßãËØ≠Èü≥ÂêàÊàê: '{text}'")

            # 7. ÊâßË°åÊé®ÁêÜ
            sr, audio_data = next(tts_pipeline.run(inference_params))

            # 8. ËΩ¨Êç¢‰∏∫16bit PCM
            if audio_data.dtype != np.int16:
                audio_data = (audio_data * 32768).astype(np.int16)

            # 9. ÂàõÂª∫WAVÊñá‰ª∂
            wav_data = self._create_wav_file(audio_data.tobytes(), sr)

            logger.info(f"‚úÖ Êé®ÁêÜÂÆåÊàêÔºåÈü≥È¢ëÂ§ßÂ∞è: {len(wav_data)} bytes, ÈááÊ†∑Áéá: {sr}Hz")

            # 10. Ê∏ÖÁêÜËµÑÊ∫ê
            del tts_pipeline
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

            return wav_data

        except Exception as e:
            logger.error(f"‚ùå GPT-SoVITSÊé®ÁêÜÂ§±Ë¥•: {e}")
            logger.error(f"ËØ¶ÁªÜÈîôËØØ: {traceback.format_exc()}")
            return b""

    def _create_tts_config(self, gpt_path: str, sovits_path: str):
        """ÂàõÂª∫TTSÈÖçÁΩÆÂ≠óÂÖ∏"""
        # ËÆ°ÁÆóÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãÁöÑÁªùÂØπË∑ØÂæÑ
        pretrained_dir = os.path.join(self.gpt_sovits_path, "pretrained_models")
        bert_path = os.path.join(pretrained_dir, "chinese-roberta-wwm-ext-large")
        cnhubert_path = os.path.join(pretrained_dir, "chinese-hubert-base")

        # ÂàõÂª∫customÈÖçÁΩÆÔºàTTS_ConfigÊúüÊúõÁöÑÊ†ºÂºèÔºâ
        custom_config = {
            "device": self.device,
            "is_half": True if self.device == "cuda" else False,
            "version": "v2Pro",
            "t2s_weights_path": gpt_path,
            "vits_weights_path": sovits_path,
            "bert_base_path": bert_path,
            "cnhuhbert_base_path": cnhubert_path
        }

        # ËøîÂõûÂåÖÂê´customÈîÆÁöÑÈÖçÁΩÆÂ≠óÂÖ∏
        return {"custom": custom_config}

    def _get_default_model_paths(self):
        """Ëé∑ÂèñÈªòËÆ§Ê®°ÂûãË∑ØÂæÑÔºà‰ªéÈÖçÁΩÆÊñá‰ª∂‰∏≠ËØªÂèñÔºâ"""
        try:
            # ‰ªéÈÖçÁΩÆÊñá‰ª∂‰∏≠ËØªÂèñÊ®°ÂûãÁõÆÂΩï
            model_paths = self.config.get("model_paths", {})
            gpt_dir = model_paths.get("gpt_weights_dir", "./GPT_weights_v2Pro")
            sovits_dir = model_paths.get("sovits_weights_dir", "./SoVITS_weights_v2Pro")

            # ËΩ¨Êç¢‰∏∫ÁªùÂØπË∑ØÂæÑ
            current_dir = os.path.dirname(os.path.abspath(__file__))
            project_root = os.path.abspath(os.path.join(current_dir, "../../.."))

            gpt_weights_dir = os.path.join(project_root, gpt_dir.lstrip("./"))
            sovits_weights_dir = os.path.join(project_root, sovits_dir.lstrip("./"))

            # ‰ΩøÁî®ÈªòËÆ§ËßíËâ≤ "ÁéãËÄÅÂ∏à" ÁöÑÊ®°Âûã
            default_role = "ÁéãËÄÅÂ∏à"
            role_config = self.config.get("role_voice_mapping", {}).get(default_role)

            if role_config:
                gpt_model = role_config.get("gpt_model")
                sovits_model = role_config.get("sovits_model")

                if gpt_model and sovits_model:
                    gpt_path = os.path.join(gpt_weights_dir, gpt_model)
                    sovits_path = os.path.join(sovits_weights_dir, sovits_model)

                    # Ê£ÄÊü•Êñá‰ª∂ÊòØÂê¶Â≠òÂú®
                    if os.path.exists(gpt_path) and os.path.exists(sovits_path):
                        return gpt_path, sovits_path

            # Â¶ÇÊûúÈªòËÆ§ËßíËâ≤Ê®°Âûã‰∏çÂ≠òÂú®Ôºå‰ΩøÁî®Á¨¨‰∏Ä‰∏™ÂèØÁî®ÁöÑÊ®°Âûã
            gpt_models = self._get_available_models("gpt")
            sovits_models = self._get_available_models("sovits")

            if gpt_models and sovits_models:
                gpt_path = os.path.join(gpt_weights_dir, gpt_models[0])
                sovits_path = os.path.join(sovits_weights_dir, sovits_models[0])
                return gpt_path, sovits_path

            # Â¶ÇÊûúÈÉΩÊ≤°ÊúâÔºåËøîÂõûNone
            return None, None

        except Exception as e:
            logger.error(f"Ëé∑ÂèñÈªòËÆ§Ê®°ÂûãË∑ØÂæÑÂ§±Ë¥•: {e}")
            return None, None

    def _get_role_config_by_model(self, gpt_path: str, sovits_path: str) -> Optional[Dict]:
        """Ê†πÊçÆÊ®°ÂûãË∑ØÂæÑËé∑ÂèñËßíËâ≤ÈÖçÁΩÆ"""
        gpt_model = os.path.basename(gpt_path)
        sovits_model = os.path.basename(sovits_path)

        for role_name, config in self.config.get("role_voice_mapping", {}).items():
            if (config.get("gpt_model") == gpt_model and
                config.get("sovits_model") == sovits_model):
                # Ê∑ªÂä†ÂèÇËÄÉÈü≥È¢ëË∑ØÂæÑ
                current_dir = os.path.dirname(os.path.abspath(__file__))
                ref_audio_name = config.get("ref_audio", "")
                # Â∞ùËØïÂ§ö‰∏™ÂèØËÉΩÁöÑË∑ØÂæÑ
                possible_paths = [
                    os.path.join(current_dir, "../../../GPT-Sovits-slice", ref_audio_name),
                    os.path.join(current_dir, "../../../GPT-Sovits-slice", ref_audio_name.replace("-slicer", "")),
                    os.path.join(current_dir, "../../../GPT-Sovits-slice", f"{role_name}.wav"),
                    os.path.join(current_dir, "../../../GPT-Sovits-slice", f"{gpt_model.split('-')[0]}.wav")
                ]

                ref_audio_path = None
                for path in possible_paths:
                    if os.path.exists(path):
                        ref_audio_path = path
                        break

                if not ref_audio_path:
                    logger.warning(f"‚ö†Ô∏è ÂèÇËÄÉÈü≥È¢ë‰∏çÂ≠òÂú®: {possible_paths[0]}")
                    # ‰ΩøÁî®Á¨¨‰∏Ä‰∏™ÂèØËÉΩÁöÑË∑ØÂæÑ‰Ωú‰∏∫ÈªòËÆ§ÂÄº
                    ref_audio_path = possible_paths[0]

                return {
                    **config,
                    "ref_audio_path": ref_audio_path
                }

        return None

    def _create_wav_file(self, pcm_data: bytes, sample_rate: int = 44100) -> bytes:
        """
        ÂàõÂª∫WAVÊñá‰ª∂Ê†ºÂºè

        Args:
            pcm_data: PCMÈü≥È¢ëÊï∞ÊçÆÔºà16bit, ÂçïÂ£∞ÈÅìÔºâ
            sample_rate: ÈááÊ†∑Áéá

        Returns:
            ÂÆåÊï¥ÁöÑWAVÊñá‰ª∂Êï∞ÊçÆ
        """
        try:
            # WAVÊñá‰ª∂Â§¥ÁªìÊûÑ
            # RIFFÂ§¥
            riff_header = b'RIFF'
            file_size = 36 + len(pcm_data)  # 36ÊòØWAVÂ§¥ÁöÑÂõ∫ÂÆöÂ§ßÂ∞è
            riff_size = file_size.to_bytes(4, 'little')

            # WAVEÊ†áËØÜ
            wave_header = b'WAVE'

            # fmtÂ≠êÂùó
            fmt_header = b'fmt '
            fmt_size = (16).to_bytes(4, 'little')  # fmtÂ≠êÂùóÂ§ßÂ∞è
            audio_format = (1).to_bytes(2, 'little')  # PCMÊ†ºÂºè
            num_channels = (1).to_bytes(2, 'little')  # ÂçïÂ£∞ÈÅì
            sample_rate_bytes = sample_rate.to_bytes(4, 'little')
            byte_rate = (sample_rate * 1 * 16 // 8).to_bytes(4, 'little')  # Â≠óËäÇÁéá
            block_align = (1 * 16 // 8).to_bytes(2, 'little')  # ÂùóÂØπÈΩê
            bits_per_sample = (16).to_bytes(2, 'little')  # 16‰Ωç

            # dataÂ≠êÂùó
            data_header = b'data'
            data_size = len(pcm_data).to_bytes(4, 'little')

            # ÁªÑÂêàÊâÄÊúâÈÉ®ÂàÜ
            wav_file = (
                riff_header + riff_size + wave_header +
                fmt_header + fmt_size + audio_format + num_channels +
                sample_rate_bytes + byte_rate + block_align + bits_per_sample +
                data_header + data_size + pcm_data
            )

            logger.info(f"‚úÖ WAVÊñá‰ª∂ÂàõÂª∫ÊàêÂäü: {len(wav_file)} bytes, ÈááÊ†∑Áéá: {sample_rate}Hz")
            return wav_file

        except Exception as e:
            logger.error(f"‚ùå ÂàõÂª∫WAVÊñá‰ª∂Â§±Ë¥•: {e}")
            return b""

    def _get_role_config(self, role_name: str) -> Optional[Dict]:
        """Ëé∑ÂèñËßíËâ≤ÈÖçÁΩÆ"""
        return self.config.get("role_voice_mapping", {}).get(role_name)

    def get_available_roles(self) -> List[Dict]:
        """Ëé∑ÂèñÂèØÁî®ËßíËâ≤ÂàóË°®"""
        roles = []
        for role_name, config in self.config.get("role_voice_mapping", {}).items():
            roles.append({
                "name": role_name,
                "description": config.get("description", ""),
                "gpt_model": config.get("gpt_model"),
                "sovits_model": config.get("sovits_model"),
                "voice_params": config.get("voice_params", {})
            })
        return roles

    def is_model_available(self, role_name: str) -> bool:
        """Ê£ÄÊü•ËßíËâ≤Ê®°ÂûãÊòØÂê¶ÂèØÁî®"""
        role_config = self._get_role_config(role_name)
        if not role_config:
            return False

        gpt_model = role_config.get("gpt_model")
        sovits_model = role_config.get("sovits_model")

        gpt_path = os.path.join(self.gpt_weights_dir, gpt_model)
        sovits_path = os.path.join(self.sovits_weights_dir, sovits_model)

        return os.path.exists(gpt_path) and os.path.exists(sovits_path)

    async def health_check(self) -> Dict:
        """ÂÅ•Â∫∑Ê£ÄÊü•"""
        try:
            available_roles = self.get_available_roles()
            working_roles = [role for role in available_roles if self.is_model_available(role["name"])]

            return {
                "service": "gpt_sovits",
                "device": self.device,
                "total_roles": len(available_roles),
                "working_roles": len(working_roles),
                "gpt_weights_dir": self.gpt_weights_dir,
                "sovits_weights_dir": self.sovits_weights_dir,
                "models_loaded": len(self.models_cache)
            }

        except Exception as e:
            return {
                "service": "gpt_sovits",
                "error": str(e),
                "device": self.device
            }

# ÂÖ®Â±ÄÊúçÂä°ÂÆû‰æã
gpt_sovits_service = GPTSoVITSService()
