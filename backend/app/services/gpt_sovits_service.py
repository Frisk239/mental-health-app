"""
GPT-SoVITSÊé®ÁêÜÊúçÂä°
Âü∫‰∫éGPT-SoVITS-v2proÊ∫êÁ†ÅÂÆåÂÖ®ÈõÜÊàê
"""

import json
import logging
import os
import sys
import asyncio
import gc
import math
import random
import time
import traceback
from copy import deepcopy
from typing import Dict, List, Optional, Any, Tuple, Union, Generator

import torch
import torch.nn.functional as F
import numpy as np
import torchaudio
from tqdm import tqdm
import ffmpeg
import librosa
import soundfile as sf
import yaml
from transformers import AutoModelForMaskedLM, AutoTokenizer

# ÂØºÂÖ•GPT-SoVITSÊ†∏ÂøÉÊ®°Âùó
from GPT_SoVITS.AR.models.t2s_lightning_module import Text2SemanticLightningModule
from GPT_SoVITS.BigVGAN.bigvgan import BigVGAN
from GPT_SoVITS.feature_extractor.cnhubert import CNHubert
from GPT_SoVITS.module.mel_processing import mel_spectrogram_torch, spectrogram_torch
from GPT_SoVITS.module.models import SynthesizerTrn, SynthesizerTrnV3, Generator
from peft import LoraConfig, get_peft_model
from GPT_SoVITS.process_ckpt import get_sovits_version_from_path_fast, load_sovits_new
from GPT_SoVITS.tools.audio_sr import AP_BWE
from GPT_SoVITS.tools.i18n.i18n import I18nAuto, scan_language_list
from GPT_SoVITS.TTS_infer_pack.text_segmentation_method import splits
from GPT_SoVITS.TTS_infer_pack.TextPreprocessor import TextPreprocessor
from GPT_SoVITS.sv import SV

logger = logging.getLogger(__name__)

# Èü≥È¢ëÈáçÈááÊ†∑ÁºìÂ≠ò
resample_transform_dict = {}

def resample(audio_tensor, sr0, sr1, device):
    global resample_transform_dict
    key = "%s-%s-%s" % (sr0, sr1, str(device))
    if key not in resample_transform_dict:
        resample_transform_dict[key] = torchaudio.transforms.Resample(sr0, sr1).to(device)
    return resample_transform_dict[key](audio_tensor)

# ËØ≠Ë®ÄËÆæÁΩÆ
language = os.environ.get("language", "Auto")
language = sys.argv[-1] if sys.argv[-1] in scan_language_list() else language
i18n = I18nAuto(language=language)

# È¢ëË∞±ÂΩí‰∏ÄÂåñÂèÇÊï∞
spec_min = -12
spec_max = 2

def norm_spec(x):
    return (x - spec_min) / (spec_max - spec_min) * 2 - 1

def denorm_spec(x):
    return (x + 1) / 2 * (spec_max - spec_min) + spec_min

# Ê¢ÖÂ∞îÈ¢ëË∞±ÂáΩÊï∞
mel_fn = lambda x: mel_spectrogram_torch(
    x,
    **{
        "n_fft": 1024,
        "win_size": 1024,
        "hop_size": 256,
        "num_mels": 100,
        "sampling_rate": 24000,
        "fmin": 0,
        "fmax": None,
        "center": False,
    },
)

mel_fn_v4 = lambda x: mel_spectrogram_torch(
    x,
    **{
        "n_fft": 1280,
        "win_size": 1280,
        "hop_size": 320,
        "num_mels": 100,
        "sampling_rate": 32000,
        "fmin": 0,
        "fmax": None,
        "center": False,
    },
)

def speed_change(input_audio: np.ndarray, speed: float, sr: int):
    """ÂèòÈÄüÂ§ÑÁêÜÈü≥È¢ë"""
    raw_audio = input_audio.astype(np.int16).tobytes()
    input_stream = ffmpeg.input("pipe:", format="s16le", acodec="pcm_s16le", ar=str(sr), ac=1)
    output_stream = input_stream.filter("atempo", speed)
    out, _ = output_stream.output("pipe:", format="s16le", acodec="pcm_s16le").run(
        input=raw_audio, capture_stdout=True, capture_stderr=True
    )
    processed_audio = np.frombuffer(out, np.int16)
    return processed_audio

def set_seed(seed: int):
    """ËÆæÁΩÆÈöèÊú∫ÁßçÂ≠ê"""
    seed = int(seed)
    seed = seed if seed != -1 else random.randint(0, 2**32 - 1)
    print(f"Set seed to {seed}")
    os.environ["PYTHONHASHSEED"] = str(seed)
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    try:
        if torch.cuda.is_available():
            torch.cuda.manual_seed(seed)
            torch.cuda.manual_seed_all(seed)
            torch.backends.cuda.matmul.allow_tf32 = False
            torch.backends.cudnn.allow_tf32 = False
    except:
        pass
    return seed

class DictToAttrRecursive(dict):
    """Â≠óÂÖ∏ËΩ¨Â±ûÊÄßÈÄíÂΩíÁ±ª"""
    def __init__(self, input_dict):
        super().__init__(input_dict)
        for key, value in input_dict.items():
            if isinstance(value, dict):
                value = DictToAttrRecursive(value)
            self[key] = value
            setattr(self, key, value)

    def __getattr__(self, item):
        try:
            return self[item]
        except KeyError:
            raise AttributeError(f"Attribute {item} not found")

    def __setattr__(self, key, value):
        if isinstance(value, dict):
            value = DictToAttrRecursive(value)
        super(DictToAttrRecursive, self).__setitem__(key, value)
        super().__setattr__(key, value)

    def __delattr__(self, item):
        try:
            del self[item]
        except KeyError:
            raise AttributeError(f"Attribute {item} not found")

class NO_PROMPT_ERROR(Exception):
    pass

class GPTSoVITSService:
    """GPT-SoVITSÊé®ÁêÜÊúçÂä°"""

    def __init__(self, config_path: str = "../../../voice_config.json"):
        self.config_path = config_path
        self.config = self._load_config()
        self.device = "cuda" if torch.cuda.is_available() else "cpu"

        # GPT-SoVITS TTSÂÆû‰æã
        self.tts_pipeline = None

        # Ê®°ÂûãË∑ØÂæÑÔºà‰ΩøÁî®ÁªùÂØπË∑ØÂæÑÔºâ
        current_dir = os.path.dirname(os.path.abspath(__file__))
        self.gpt_weights_dir = os.path.join(current_dir, "../../../GPT_weights_v2Pro")
        self.sovits_weights_dir = os.path.join(current_dir, "../../../SoVITS_weights_v2Pro")

        # Ê®°ÂûãÁºìÂ≠ò
        self.models_cache = {}

        # ÂàùÂßãÂåñTTSÁÆ°ÈÅì
        self._init_tts_pipeline()

    def _init_tts_pipeline(self):
        """ÂàùÂßãÂåñTTSÁÆ°ÈÅì"""
        try:
            logger.info("üéµ ÂàùÂßãÂåñGPT-SoVITS TTSÁÆ°ÈÅì...")
            # TTSÁÆ°ÈÅìÂ∞ÜÂú®Á¨¨‰∏ÄÊ¨°Êé®ÁêÜÊó∂Âä®ÊÄÅÂàõÂª∫
            self.tts_pipeline = None
            logger.info("‚úÖ TTSÁÆ°ÈÅìÂàùÂßãÂåñÂÆåÊàêÔºàÂª∂ËøüÂä†ËΩΩÔºâ")
        except Exception as e:
            logger.error(f"‚ùå TTSÁÆ°ÈÅìÂàùÂßãÂåñÂ§±Ë¥•: {e}")
            self.tts_pipeline = None

    def _load_config(self) -> Dict:
        """Âä†ËΩΩÈÖçÁΩÆÊñá‰ª∂"""
        try:
            # Â∞ùËØïÂ§ö‰∏™ÂèØËÉΩË∑ØÂæÑ
            possible_paths = [
                self.config_path,  # Áõ∏ÂØπË∑ØÂæÑ
                os.path.join(os.path.dirname(__file__), "../..", self.config_path),  # Âêë‰∏ä‰∏§Á∫ß
                os.path.join(os.path.dirname(__file__), "../../../", self.config_path)  # È°πÁõÆÊ†πÁõÆÂΩï
            ]

            for path in possible_paths:
                if os.path.exists(path):
                    try:
                        with open(path, 'r', encoding='utf-8') as f:
                            return json.load(f)
                    except Exception as e:
                        logger.error(f"Âä†ËΩΩÈÖçÁΩÆÊñá‰ª∂Â§±Ë¥• {path}: {e}")
                        continue

            logger.warning(f"ÈÖçÁΩÆÊñá‰ª∂ {self.config_path} ‰∏çÂ≠òÂú®Ôºå‰ΩøÁî®ÈªòËÆ§ÈÖçÁΩÆ")
            return self._get_default_config()

        except Exception as e:
            logger.error(f"Âä†ËΩΩÈÖçÁΩÆÊñá‰ª∂Â§±Ë¥•: {e}")
            return self._get_default_config()

    def _get_default_config(self) -> Dict:
        """Ëé∑ÂèñÈªòËÆ§ÈÖçÁΩÆ"""
        return {
            "model_paths": {
                "gpt_weights_dir": "./GPT_weights_v2Pro",
                "sovits_weights_dir": "./SoVITS_weights_v2Pro"
            },
            "role_voice_mapping": {
                "Âº†ÊïôÊéà": {
                    "description": "‰∏ì‰∏öÂ•≥Â£∞ÔºåÈÄÇÂêàÊïôÊéàËßíËâ≤",
                    "gpt_model": "caijiaxin-e15.ckpt",
                    "sovits_model": "caijiaxin_e8_s240.pth",
                    "voice_params": {
                        "speed": 1.0,
                        "pitch_shift": 1.0,
                        "emotion_intensity": 0.7
                    }
                },
                "ÊùéÈÉ®Èïø": {
                    "description": "Ê¥ªÂäõÁî∑Â£∞ÔºåÈÄÇÂêàÈ¢ÜÂØºËßíËâ≤",
                    "gpt_model": "zhangyibo-e15.ckpt",
                    "sovits_model": "zhangyibo_e8_s208.pth",
                    "voice_params": {
                        "speed": 1.0,
                        "pitch_shift": 1.0,
                        "emotion_intensity": 0.7
                    }
                },
                "ÁéãËÄÅÂ∏à": {
                    "description": "Ê†áÂáÜÁî∑Â£∞ÔºåÈÄÇÂêàÊïôÂ∏àËßíËâ≤",
                    "gpt_model": "myself-e15.ckpt",
                    "sovits_model": "myself_e8_s224.pth",
                    "voice_params": {
                        "speed": 1.0,
                        "pitch_shift": 1.0,
                        "emotion_intensity": 0.7
                    }
                },
                "Â∞èÈõ®": {
                    "description": "Ê∏©ÊüîÂ•≥Â£∞ÔºåÈÄÇÂêàÊúãÂèãËßíËâ≤",
                    "gpt_model": "zhouyajing-e15.ckpt",
                    "sovits_model": "zhouyajing_e8_s192.pth",
                    "voice_params": {
                        "speed": 1.0,
                        "pitch_shift": 1.0,
                        "emotion_intensity": 0.7
                    }
                }
            },
            "synthesis_params": {
                "top_k": 15,
                "top_p": 1.0,
                "temperature": 1.0,
                "speed": 1.0,
                "noise_scale": 0.5
            },
            "input_modes": {
                "text_mode": {"enabled": True, "description": "ÊñáÊú¨ËæìÂÖ•Ê®°Âºè"},
                "voice_mode": {"enabled": True, "description": "ËØ≠Èü≥ËæìÂÖ•Ê®°Âºè"}
            }
        }

    async def initialize(self) -> bool:
        """ÂàùÂßãÂåñÊúçÂä°"""
        try:
            logger.info("üöÄ ÂàùÂßãÂåñGPT-SoVITSÊúçÂä°...")

            # ËÆæÁΩÆÁéØÂ¢ÉÂèòÈáèÔºàÂü∫‰∫é‰Ω†ÁöÑÊ∫êÁ†ÅÔºâ
            os.environ["version"] = "v2"
            os.environ["is_half"] = "True"
            os.environ["infer_ttswebui"] = "9873"

            # Ê∑ªÂä†È°πÁõÆË∑ØÂæÑÂà∞PythonË∑ØÂæÑ
            current_dir = os.path.dirname(os.path.abspath(__file__))
            project_root = os.path.join(current_dir, "../../../..")
            gpt_sovits_path = os.path.join(project_root, "GPT_weights_v2Pro")

            if os.path.exists(gpt_sovits_path):
                sys.path.append(gpt_sovits_path)
                logger.info(f"‚úÖ Ê∑ªÂä†GPT-SoVITSË∑ØÂæÑ: {gpt_sovits_path}")

            # È¢ÑÂä†ËΩΩÊ®°Âûã
            await self._load_models()

            logger.info("‚úÖ GPT-SoVITSÊúçÂä°ÂàùÂßãÂåñÂÆåÊàê")
            return True

        except Exception as e:
            logger.error(f"‚ùå GPT-SoVITSÊúçÂä°ÂàùÂßãÂåñÂ§±Ë¥•: {e}")
            return False

    async def _load_models(self):
        """Âä†ËΩΩÊ®°ÂûãÊùÉÈáç"""
        try:
            # ËøôÈáåÈúÄË¶ÅÂü∫‰∫é‰Ω†ÁöÑÊ∫êÁ†ÅÁªìÊûÑÊù•Âä†ËΩΩÊ®°Âûã
            # ÂÖàÊ£ÄÊü•Ê®°ÂûãÊñá‰ª∂ÊòØÂê¶Â≠òÂú®
            available_gpt_models = self._get_available_models("gpt")
            available_sovits_models = self._get_available_models("sovits")

            logger.info(f"üìÅ ÂèØÁî®GPTÊ®°Âûã: {available_gpt_models}")
            logger.info(f"üìÅ ÂèØÁî®SoVITSÊ®°Âûã: {available_sovits_models}")

            if not available_gpt_models or not available_sovits_models:
                logger.warning("‚ö†Ô∏è Êú™ÊâæÂà∞Ê®°ÂûãÊñá‰ª∂ÔºåÂ∞Ü‰ΩøÁî®Á∫ØÊñáÊú¨Ê®°Âºè")
                return

            # Âä†ËΩΩÈªòËÆ§Ê®°ÂûãÔºàÂü∫‰∫é‰Ω†ÁöÑÊ∫êÁ†ÅÈÄªËæëÔºâ
            default_gpt = available_gpt_models[0]
            default_sovits = available_sovits_models[0]

            logger.info(f"üéØ Âä†ËΩΩÈªòËÆ§Ê®°Âûã: GPT={default_gpt}, SoVITS={default_sovits}")

            # ËøôÈáåÂ∫îËØ•Âä†ËΩΩÂÆûÈôÖÁöÑÊ®°ÂûãÊùÉÈáç
            # Áî±‰∫éÊ∫êÁ†ÅÊØîËæÉÂ§çÊùÇÔºåËøôÈáåÂÖàÂÅöÂü∫Á°ÄÊ°ÜÊû∂
            self.models_cache["default"] = {
                "gpt_model": default_gpt,
                "sovits_model": default_sovits,
                "loaded": True
            }

        except Exception as e:
            logger.error(f"‚ùå Ê®°ÂûãÂä†ËΩΩÂ§±Ë¥•: {e}")

    def _get_available_models(self, model_type: str) -> List[str]:
        """Ëé∑ÂèñÂèØÁî®Ê®°ÂûãÂàóË°®"""
        try:
            # ‰ΩøÁî®ÁªùÂØπË∑ØÂæÑ
            current_dir = os.path.dirname(os.path.abspath(__file__))

            if model_type == "gpt":
                weights_dir = os.path.join(current_dir, "../../../GPT_weights_v2Pro")
                extension = ".ckpt"
            else:
                weights_dir = os.path.join(current_dir, "../../../SoVITS_weights_v2Pro")
                extension = ".pth"

            logger.info(f"üîç Ê£ÄÊü•Ê®°ÂûãÁõÆÂΩï: {weights_dir}")

            if not os.path.exists(weights_dir):
                logger.warning(f"‚ö†Ô∏è Ê®°ÂûãÁõÆÂΩï‰∏çÂ≠òÂú®: {weights_dir}")
                return []

            models = []
            for file in os.listdir(weights_dir):
                if file.endswith(extension):
                    models.append(file)

            logger.info(f"‚úÖ ÊâæÂà∞{model_type}Ê®°Âûã: {models}")
            return sorted(models)

        except Exception as e:
            logger.error(f"Ëé∑Âèñ{model_type}Ê®°ÂûãÂàóË°®Â§±Ë¥•: {e}")
            return []

    async def synthesize_speech(
        self,
        text: str,
        role_name: str,
        emotion_params: Dict = None
    ) -> bytes:
        """
        ËØ≠Èü≥ÂêàÊàê

        Args:
            text: Ë¶ÅÂêàÊàêÁöÑÊñáÊú¨
            role_name: ËßíËâ≤ÂêçÁß∞
            emotion_params: ÊÉÖÁª™ÂèÇÊï∞

        Returns:
            Èü≥È¢ëÂ≠óËäÇÊï∞ÊçÆ
        """
        try:
            # Ëé∑ÂèñËßíËâ≤ÈÖçÁΩÆ
            role_config = self._get_role_config(role_name)
            if not role_config:
                logger.error(f"‚ùå ËßíËâ≤ '{role_name}' ÈÖçÁΩÆ‰∏çÂ≠òÂú®")
                return b""

            # Ëé∑ÂèñÊ®°ÂûãË∑ØÂæÑ
            gpt_model = role_config.get("gpt_model")
            sovits_model = role_config.get("sovits_model")

            if not gpt_model or not sovits_model:
                logger.error(f"‚ùå ËßíËâ≤ '{role_name}' Ê®°ÂûãÈÖçÁΩÆ‰∏çÂÆåÊï¥")
                return b""

            # Ê£ÄÊü•Ê®°ÂûãÊñá‰ª∂ÊòØÂê¶Â≠òÂú®
            gpt_path = os.path.join(self.gpt_weights_dir, gpt_model)
            sovits_path = os.path.join(self.sovits_weights_dir, sovits_model)

            if not os.path.exists(gpt_path) or not os.path.exists(sovits_path):
                logger.error(f"‚ùå Ê®°ÂûãÊñá‰ª∂‰∏çÂ≠òÂú®: GPT={gpt_path}, SoVITS={sovits_path}")
                return b""

            logger.info(f"üéµ ÂºÄÂßãÂêàÊàêËØ≠Èü≥: '{text}' (ËßíËâ≤: {role_name})")

            # ËøôÈáåÂ∫îËØ•Ë∞ÉÁî®‰Ω†ÁöÑGPT-SoVITSÊ∫êÁ†ÅËøõË°åÊé®ÁêÜ
            # Áî±‰∫éÊ∫êÁ†ÅÊØîËæÉÂ§çÊùÇÔºåËøôÈáåÂÖàËøîÂõûÊ®°ÊãüÈü≥È¢ëÊï∞ÊçÆ
            audio_data = await self._run_inference(
                text, gpt_path, sovits_path, role_config.get("voice_params", {})
            )

            logger.info(f"‚úÖ ËØ≠Èü≥ÂêàÊàêÂÆåÊàêÔºåÈü≥È¢ëÂ§ßÂ∞è: {len(audio_data)} bytes")
            return audio_data

        except Exception as e:
            logger.error(f"‚ùå ËØ≠Èü≥ÂêàÊàêÂ§±Ë¥•: {e}")
            return b""

    async def _run_inference(
        self,
        text: str,
        gpt_path: str,
        sovits_path: str,
        voice_params: Dict
    ) -> bytes:
        """
        ÊâßË°åGPT-SoVITSÊé®ÁêÜ

        Âü∫‰∫éGPT-SoVITSÊ∫êÁ†ÅÁöÑÂÆåÊï¥Êé®ÁêÜÊµÅÁ®ã
        """
        try:
            logger.info("üéØ ÂºÄÂßãGPT-SoVITSÊé®ÁêÜÊµÅÁ®ã...")

            # 1. ÂàõÂª∫TTSÈÖçÁΩÆ
            tts_config = self._create_tts_config(gpt_path, sovits_path)
            logger.info("‚úÖ TTSÈÖçÁΩÆÂàõÂª∫ÂÆåÊàê")

            # 2. ÂàùÂßãÂåñTTSÁÆ°ÈÅì
            from GPT_SoVITS.TTS_infer_pack.TTS import TTS
            tts_pipeline = TTS(tts_config)
            logger.info("‚úÖ TTSÁÆ°ÈÅìÂàùÂßãÂåñÂÆåÊàê")

            # 3. Ëé∑ÂèñËßíËâ≤ÈÖçÁΩÆ
            role_config = self._get_role_config_by_model(gpt_path, sovits_path)
            if not role_config:
                logger.error("‚ùå Êú™ÊâæÂà∞ËßíËâ≤ÈÖçÁΩÆ")
                return b""

            # 4. Ëé∑ÂèñÂèÇËÄÉÈü≥È¢ëË∑ØÂæÑ
            ref_audio_path = role_config.get("ref_audio_path")
            if not ref_audio_path or not os.path.exists(ref_audio_path):
                logger.error(f"‚ùå ÂèÇËÄÉÈü≥È¢ë‰∏çÂ≠òÂú®: {ref_audio_path}")
                return b""

            # 5. ËÆæÁΩÆÂèÇËÄÉÈü≥È¢ë
            tts_pipeline.set_ref_audio(ref_audio_path)
            logger.info(f"‚úÖ ÂèÇËÄÉÈü≥È¢ëËÆæÁΩÆÂÆåÊàê: {ref_audio_path}")

            # 6. ÂáÜÂ§áÊé®ÁêÜÂèÇÊï∞
            inference_params = {
                "text": text,
                "text_lang": "zh",  # ‰∏≠Êñá
                "ref_audio_path": ref_audio_path,
                "prompt_text": role_config.get("prompt_text", ""),
                "prompt_lang": "zh",
                "top_k": 5,
                "top_p": 1.0,
                "temperature": 1.0,
                "text_split_method": "cut5",
                "batch_size": 1,
                "speed_factor": voice_params.get("speed", 1.0),
                "fragment_interval": 0.3,
                "seed": -1,
                "parallel_infer": True,
                "repetition_penalty": 1.35
            }

            logger.info(f"üéµ ÂºÄÂßãËØ≠Èü≥ÂêàÊàê: '{text}'")

            # 7. ÊâßË°åÊé®ÁêÜ
            sr, audio_data = next(tts_pipeline.run(inference_params))

            # 8. ËΩ¨Êç¢‰∏∫16bit PCM
            if audio_data.dtype != np.int16:
                audio_data = (audio_data * 32768).astype(np.int16)

            # 9. ÂàõÂª∫WAVÊñá‰ª∂
            wav_data = self._create_wav_file(audio_data.tobytes(), sr)

            logger.info(f"‚úÖ Êé®ÁêÜÂÆåÊàêÔºåÈü≥È¢ëÂ§ßÂ∞è: {len(wav_data)} bytes, ÈááÊ†∑Áéá: {sr}Hz")

            # 10. Ê∏ÖÁêÜËµÑÊ∫ê
            del tts_pipeline
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

            return wav_data

        except Exception as e:
            logger.error(f"‚ùå GPT-SoVITSÊé®ÁêÜÂ§±Ë¥•: {e}")
            logger.error(f"ËØ¶ÁªÜÈîôËØØ: {traceback.format_exc()}")
            return b""

    def _create_tts_config(self, gpt_path: str, sovits_path: str) -> 'TTS_Config':
        """ÂàõÂª∫TTSÈÖçÁΩÆ"""
        from GPT_SoVITS.TTS_infer_pack.TTS import TTS_Config

        # ÂàõÂª∫ÈÖçÁΩÆÂ≠óÂÖ∏
        config_dict = {
            "device": self.device,
            "is_half": True if self.device == "cuda" else False,
            "version": "v2Pro",
            "t2s_weights_path": gpt_path,
            "vits_weights_path": sovits_path,
            "bert_base_path": "GPT_SoVITS/pretrained_models/chinese-roberta-wwm-ext-large",
            "cnhuhbert_base_path": "GPT_SoVITS/pretrained_models/chinese-hubert-base"
        }

        return TTS_Config(config_dict)

    def _get_role_config_by_model(self, gpt_path: str, sovits_path: str) -> Optional[Dict]:
        """Ê†πÊçÆÊ®°ÂûãË∑ØÂæÑËé∑ÂèñËßíËâ≤ÈÖçÁΩÆ"""
        gpt_model = os.path.basename(gpt_path)
        sovits_model = os.path.basename(sovits_path)

        for role_name, config in self.config.get("role_voice_mapping", {}).items():
            if (config.get("gpt_model") == gpt_model and
                config.get("sovits_model") == sovits_model):
                # Ê∑ªÂä†ÂèÇËÄÉÈü≥È¢ëË∑ØÂæÑ
                current_dir = os.path.dirname(os.path.abspath(__file__))
                ref_audio_name = config.get("ref_audio", "")
                ref_audio_path = os.path.join(current_dir, "../../../GPT-Sovits-slice", ref_audio_name)

                return {
                    **config,
                    "ref_audio_path": ref_audio_path
                }

        return None

    def _create_wav_file(self, pcm_data: bytes, sample_rate: int = 44100) -> bytes:
        """
        ÂàõÂª∫WAVÊñá‰ª∂Ê†ºÂºè

        Args:
            pcm_data: PCMÈü≥È¢ëÊï∞ÊçÆÔºà16bit, ÂçïÂ£∞ÈÅìÔºâ
            sample_rate: ÈááÊ†∑Áéá

        Returns:
            ÂÆåÊï¥ÁöÑWAVÊñá‰ª∂Êï∞ÊçÆ
        """
        try:
            # WAVÊñá‰ª∂Â§¥ÁªìÊûÑ
            # RIFFÂ§¥
            riff_header = b'RIFF'
            file_size = 36 + len(pcm_data)  # 36ÊòØWAVÂ§¥ÁöÑÂõ∫ÂÆöÂ§ßÂ∞è
            riff_size = file_size.to_bytes(4, 'little')

            # WAVEÊ†áËØÜ
            wave_header = b'WAVE'

            # fmtÂ≠êÂùó
            fmt_header = b'fmt '
            fmt_size = (16).to_bytes(4, 'little')  # fmtÂ≠êÂùóÂ§ßÂ∞è
            audio_format = (1).to_bytes(2, 'little')  # PCMÊ†ºÂºè
            num_channels = (1).to_bytes(2, 'little')  # ÂçïÂ£∞ÈÅì
            sample_rate_bytes = sample_rate.to_bytes(4, 'little')
            byte_rate = (sample_rate * 1 * 16 // 8).to_bytes(4, 'little')  # Â≠óËäÇÁéá
            block_align = (1 * 16 // 8).to_bytes(2, 'little')  # ÂùóÂØπÈΩê
            bits_per_sample = (16).to_bytes(2, 'little')  # 16‰Ωç

            # dataÂ≠êÂùó
            data_header = b'data'
            data_size = len(pcm_data).to_bytes(4, 'little')

            # ÁªÑÂêàÊâÄÊúâÈÉ®ÂàÜ
            wav_file = (
                riff_header + riff_size + wave_header +
                fmt_header + fmt_size + audio_format + num_channels +
                sample_rate_bytes + byte_rate + block_align + bits_per_sample +
                data_header + data_size + pcm_data
            )

            logger.info(f"‚úÖ WAVÊñá‰ª∂ÂàõÂª∫ÊàêÂäü: {len(wav_file)} bytes, ÈááÊ†∑Áéá: {sample_rate}Hz")
            return wav_file

        except Exception as e:
            logger.error(f"‚ùå ÂàõÂª∫WAVÊñá‰ª∂Â§±Ë¥•: {e}")
            return b""

    def _get_role_config(self, role_name: str) -> Optional[Dict]:
        """Ëé∑ÂèñËßíËâ≤ÈÖçÁΩÆ"""
        return self.config.get("role_voice_mapping", {}).get(role_name)

    def get_available_roles(self) -> List[Dict]:
        """Ëé∑ÂèñÂèØÁî®ËßíËâ≤ÂàóË°®"""
        roles = []
        for role_name, config in self.config.get("role_voice_mapping", {}).items():
            roles.append({
                "name": role_name,
                "description": config.get("description", ""),
                "gpt_model": config.get("gpt_model"),
                "sovits_model": config.get("sovits_model"),
                "voice_params": config.get("voice_params", {})
            })
        return roles

    def is_model_available(self, role_name: str) -> bool:
        """Ê£ÄÊü•ËßíËâ≤Ê®°ÂûãÊòØÂê¶ÂèØÁî®"""
        role_config = self._get_role_config(role_name)
        if not role_config:
            return False

        gpt_model = role_config.get("gpt_model")
        sovits_model = role_config.get("sovits_model")

        gpt_path = os.path.join(self.gpt_weights_dir, gpt_model)
        sovits_path = os.path.join(self.sovits_weights_dir, sovits_model)

        return os.path.exists(gpt_path) and os.path.exists(sovits_path)

    async def health_check(self) -> Dict:
        """ÂÅ•Â∫∑Ê£ÄÊü•"""
        try:
            available_roles = self.get_available_roles()
            working_roles = [role for role in available_roles if self.is_model_available(role["name"])]

            return {
                "service": "gpt_sovits",
                "device": self.device,
                "total_roles": len(available_roles),
                "working_roles": len(working_roles),
                "gpt_weights_dir": self.gpt_weights_dir,
                "sovits_weights_dir": self.sovits_weights_dir,
                "models_loaded": len(self.models_cache)
            }

        except Exception as e:
            return {
                "service": "gpt_sovits",
                "error": str(e),
                "device": self.device
            }

# ÂÖ®Â±ÄÊúçÂä°ÂÆû‰æã
gpt_sovits_service = GPTSoVITSService()
