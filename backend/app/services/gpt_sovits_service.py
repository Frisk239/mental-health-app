"""
GPT-SoVITSÊé®ÁêÜÊúçÂä°
Âü∫‰∫é‰Ω†ÁöÑÈ°πÁõÆÊ∫êÁ†ÅÂÆûÁé∞ËØ≠Èü≥ÂêàÊàê
"""

import json
import logging
import os
import sys
import asyncio
from typing import Dict, List, Optional, Any
import torch
import numpy as np

logger = logging.getLogger(__name__)

class GPTSoVITSService:
    """GPT-SoVITSÊé®ÁêÜÊúçÂä°"""

    def __init__(self, config_path: str = "../../../voice_config.json"):
        self.config_path = config_path
        self.config = self._load_config()
        self.device = "cuda" if torch.cuda.is_available() else "cpu"

        # Ê®°ÂûãÁªÑ‰ª∂
        self.text_encoder = None
        self.synthesizer = None
        self.vocoder = None
        self.ssl_model = None

        # Ê®°ÂûãË∑ØÂæÑÔºà‰ΩøÁî®ÁªùÂØπË∑ØÂæÑÔºâ
        current_dir = os.path.dirname(os.path.abspath(__file__))
        self.gpt_weights_dir = os.path.join(current_dir, "../../../GPT_weights_v2Pro")
        self.sovits_weights_dir = os.path.join(current_dir, "../../../SoVITS_weights_v2Pro")

        # Ê®°ÂûãÁºìÂ≠ò
        self.models_cache = {}

    def _load_config(self) -> Dict:
        """Âä†ËΩΩÈÖçÁΩÆÊñá‰ª∂"""
        try:
            # Â∞ùËØïÂ§ö‰∏™ÂèØËÉΩË∑ØÂæÑ
            possible_paths = [
                self.config_path,  # Áõ∏ÂØπË∑ØÂæÑ
                os.path.join(os.path.dirname(__file__), "../..", self.config_path),  # Âêë‰∏ä‰∏§Á∫ß
                os.path.join(os.path.dirname(__file__), "../../../", self.config_path)  # È°πÁõÆÊ†πÁõÆÂΩï
            ]

            for path in possible_paths:
                if os.path.exists(path):
                    try:
                        with open(path, 'r', encoding='utf-8') as f:
                            return json.load(f)
                    except Exception as e:
                        logger.error(f"Âä†ËΩΩÈÖçÁΩÆÊñá‰ª∂Â§±Ë¥• {path}: {e}")
                        continue

            logger.warning(f"ÈÖçÁΩÆÊñá‰ª∂ {self.config_path} ‰∏çÂ≠òÂú®Ôºå‰ΩøÁî®ÈªòËÆ§ÈÖçÁΩÆ")
            return self._get_default_config()

        except Exception as e:
            logger.error(f"Âä†ËΩΩÈÖçÁΩÆÊñá‰ª∂Â§±Ë¥•: {e}")
            return self._get_default_config()

    def _get_default_config(self) -> Dict:
        """Ëé∑ÂèñÈªòËÆ§ÈÖçÁΩÆ"""
        return {
            "model_paths": {
                "gpt_weights_dir": "./GPT_weights_v2Pro",
                "sovits_weights_dir": "./SoVITS_weights_v2Pro"
            },
            "role_voice_mapping": {
                "Âº†ÊïôÊéà": {
                    "description": "‰∏ì‰∏öÂ•≥Â£∞ÔºåÈÄÇÂêàÊïôÊéàËßíËâ≤",
                    "gpt_model": "caijiaxin-e15.ckpt",
                    "sovits_model": "caijiaxin_e8_s240.pth",
                    "voice_params": {
                        "speed": 1.0,
                        "pitch_shift": 1.0,
                        "emotion_intensity": 0.7
                    }
                },
                "ÊùéÈÉ®Èïø": {
                    "description": "Ê¥ªÂäõÁî∑Â£∞ÔºåÈÄÇÂêàÈ¢ÜÂØºËßíËâ≤",
                    "gpt_model": "zhangyibo-e15.ckpt",
                    "sovits_model": "zhangyibo_e8_s208.pth",
                    "voice_params": {
                        "speed": 1.0,
                        "pitch_shift": 1.0,
                        "emotion_intensity": 0.7
                    }
                },
                "ÁéãËÄÅÂ∏à": {
                    "description": "Ê†áÂáÜÁî∑Â£∞ÔºåÈÄÇÂêàÊïôÂ∏àËßíËâ≤",
                    "gpt_model": "myself-e15.ckpt",
                    "sovits_model": "myself_e8_s224.pth",
                    "voice_params": {
                        "speed": 1.0,
                        "pitch_shift": 1.0,
                        "emotion_intensity": 0.7
                    }
                },
                "Â∞èÈõ®": {
                    "description": "Ê∏©ÊüîÂ•≥Â£∞ÔºåÈÄÇÂêàÊúãÂèãËßíËâ≤",
                    "gpt_model": "zhouyajing-e15.ckpt",
                    "sovits_model": "zhouyajing_e8_s192.pth",
                    "voice_params": {
                        "speed": 1.0,
                        "pitch_shift": 1.0,
                        "emotion_intensity": 0.7
                    }
                }
            },
            "synthesis_params": {
                "top_k": 15,
                "top_p": 1.0,
                "temperature": 1.0,
                "speed": 1.0,
                "noise_scale": 0.5
            },
            "input_modes": {
                "text_mode": {"enabled": True, "description": "ÊñáÊú¨ËæìÂÖ•Ê®°Âºè"},
                "voice_mode": {"enabled": True, "description": "ËØ≠Èü≥ËæìÂÖ•Ê®°Âºè"}
            }
        }

    async def initialize(self) -> bool:
        """ÂàùÂßãÂåñÊúçÂä°"""
        try:
            logger.info("üöÄ ÂàùÂßãÂåñGPT-SoVITSÊúçÂä°...")

            # ËÆæÁΩÆÁéØÂ¢ÉÂèòÈáèÔºàÂü∫‰∫é‰Ω†ÁöÑÊ∫êÁ†ÅÔºâ
            os.environ["version"] = "v2"
            os.environ["is_half"] = "True"
            os.environ["infer_ttswebui"] = "9873"

            # Ê∑ªÂä†È°πÁõÆË∑ØÂæÑÂà∞PythonË∑ØÂæÑ
            current_dir = os.path.dirname(os.path.abspath(__file__))
            project_root = os.path.join(current_dir, "../../../..")
            gpt_sovits_path = os.path.join(project_root, "GPT_weights_v2Pro")

            if os.path.exists(gpt_sovits_path):
                sys.path.append(gpt_sovits_path)
                logger.info(f"‚úÖ Ê∑ªÂä†GPT-SoVITSË∑ØÂæÑ: {gpt_sovits_path}")

            # È¢ÑÂä†ËΩΩÊ®°Âûã
            await self._load_models()

            logger.info("‚úÖ GPT-SoVITSÊúçÂä°ÂàùÂßãÂåñÂÆåÊàê")
            return True

        except Exception as e:
            logger.error(f"‚ùå GPT-SoVITSÊúçÂä°ÂàùÂßãÂåñÂ§±Ë¥•: {e}")
            return False

    async def _load_models(self):
        """Âä†ËΩΩÊ®°ÂûãÊùÉÈáç"""
        try:
            # ËøôÈáåÈúÄË¶ÅÂü∫‰∫é‰Ω†ÁöÑÊ∫êÁ†ÅÁªìÊûÑÊù•Âä†ËΩΩÊ®°Âûã
            # ÂÖàÊ£ÄÊü•Ê®°ÂûãÊñá‰ª∂ÊòØÂê¶Â≠òÂú®
            available_gpt_models = self._get_available_models("gpt")
            available_sovits_models = self._get_available_models("sovits")

            logger.info(f"üìÅ ÂèØÁî®GPTÊ®°Âûã: {available_gpt_models}")
            logger.info(f"üìÅ ÂèØÁî®SoVITSÊ®°Âûã: {available_sovits_models}")

            if not available_gpt_models or not available_sovits_models:
                logger.warning("‚ö†Ô∏è Êú™ÊâæÂà∞Ê®°ÂûãÊñá‰ª∂ÔºåÂ∞Ü‰ΩøÁî®Á∫ØÊñáÊú¨Ê®°Âºè")
                return

            # Âä†ËΩΩÈªòËÆ§Ê®°ÂûãÔºàÂü∫‰∫é‰Ω†ÁöÑÊ∫êÁ†ÅÈÄªËæëÔºâ
            default_gpt = available_gpt_models[0]
            default_sovits = available_sovits_models[0]

            logger.info(f"üéØ Âä†ËΩΩÈªòËÆ§Ê®°Âûã: GPT={default_gpt}, SoVITS={default_sovits}")

            # ËøôÈáåÂ∫îËØ•Âä†ËΩΩÂÆûÈôÖÁöÑÊ®°ÂûãÊùÉÈáç
            # Áî±‰∫éÊ∫êÁ†ÅÊØîËæÉÂ§çÊùÇÔºåËøôÈáåÂÖàÂÅöÂü∫Á°ÄÊ°ÜÊû∂
            self.models_cache["default"] = {
                "gpt_model": default_gpt,
                "sovits_model": default_sovits,
                "loaded": True
            }

        except Exception as e:
            logger.error(f"‚ùå Ê®°ÂûãÂä†ËΩΩÂ§±Ë¥•: {e}")

    def _get_available_models(self, model_type: str) -> List[str]:
        """Ëé∑ÂèñÂèØÁî®Ê®°ÂûãÂàóË°®"""
        try:
            # ‰ΩøÁî®ÁªùÂØπË∑ØÂæÑ
            current_dir = os.path.dirname(os.path.abspath(__file__))

            if model_type == "gpt":
                weights_dir = os.path.join(current_dir, "../../../GPT_weights_v2Pro")
                extension = ".ckpt"
            else:
                weights_dir = os.path.join(current_dir, "../../../SoVITS_weights_v2Pro")
                extension = ".pth"

            logger.info(f"üîç Ê£ÄÊü•Ê®°ÂûãÁõÆÂΩï: {weights_dir}")

            if not os.path.exists(weights_dir):
                logger.warning(f"‚ö†Ô∏è Ê®°ÂûãÁõÆÂΩï‰∏çÂ≠òÂú®: {weights_dir}")
                return []

            models = []
            for file in os.listdir(weights_dir):
                if file.endswith(extension):
                    models.append(file)

            logger.info(f"‚úÖ ÊâæÂà∞{model_type}Ê®°Âûã: {models}")
            return sorted(models)

        except Exception as e:
            logger.error(f"Ëé∑Âèñ{model_type}Ê®°ÂûãÂàóË°®Â§±Ë¥•: {e}")
            return []

    async def synthesize_speech(
        self,
        text: str,
        role_name: str,
        emotion_params: Dict = None
    ) -> bytes:
        """
        ËØ≠Èü≥ÂêàÊàê

        Args:
            text: Ë¶ÅÂêàÊàêÁöÑÊñáÊú¨
            role_name: ËßíËâ≤ÂêçÁß∞
            emotion_params: ÊÉÖÁª™ÂèÇÊï∞

        Returns:
            Èü≥È¢ëÂ≠óËäÇÊï∞ÊçÆ
        """
        try:
            # Ëé∑ÂèñËßíËâ≤ÈÖçÁΩÆ
            role_config = self._get_role_config(role_name)
            if not role_config:
                logger.error(f"‚ùå ËßíËâ≤ '{role_name}' ÈÖçÁΩÆ‰∏çÂ≠òÂú®")
                return b""

            # Ëé∑ÂèñÊ®°ÂûãË∑ØÂæÑ
            gpt_model = role_config.get("gpt_model")
            sovits_model = role_config.get("sovits_model")

            if not gpt_model or not sovits_model:
                logger.error(f"‚ùå ËßíËâ≤ '{role_name}' Ê®°ÂûãÈÖçÁΩÆ‰∏çÂÆåÊï¥")
                return b""

            # Ê£ÄÊü•Ê®°ÂûãÊñá‰ª∂ÊòØÂê¶Â≠òÂú®
            gpt_path = os.path.join(self.gpt_weights_dir, gpt_model)
            sovits_path = os.path.join(self.sovits_weights_dir, sovits_model)

            if not os.path.exists(gpt_path) or not os.path.exists(sovits_path):
                logger.error(f"‚ùå Ê®°ÂûãÊñá‰ª∂‰∏çÂ≠òÂú®: GPT={gpt_path}, SoVITS={sovits_path}")
                return b""

            logger.info(f"üéµ ÂºÄÂßãÂêàÊàêËØ≠Èü≥: '{text}' (ËßíËâ≤: {role_name})")

            # ËøôÈáåÂ∫îËØ•Ë∞ÉÁî®‰Ω†ÁöÑGPT-SoVITSÊ∫êÁ†ÅËøõË°åÊé®ÁêÜ
            # Áî±‰∫éÊ∫êÁ†ÅÊØîËæÉÂ§çÊùÇÔºåËøôÈáåÂÖàËøîÂõûÊ®°ÊãüÈü≥È¢ëÊï∞ÊçÆ
            audio_data = await self._run_inference(
                text, gpt_path, sovits_path, role_config.get("voice_params", {})
            )

            logger.info(f"‚úÖ ËØ≠Èü≥ÂêàÊàêÂÆåÊàêÔºåÈü≥È¢ëÂ§ßÂ∞è: {len(audio_data)} bytes")
            return audio_data

        except Exception as e:
            logger.error(f"‚ùå ËØ≠Èü≥ÂêàÊàêÂ§±Ë¥•: {e}")
            return b""

    async def _run_inference(
        self,
        text: str,
        gpt_path: str,
        sovits_path: str,
        voice_params: Dict
    ) -> bytes:
        """
        ÊâßË°åÊé®ÁêÜÔºàÂü∫‰∫é‰Ω†ÁöÑÊ∫êÁ†ÅÔºâ

        ËøôÈáåÈúÄË¶ÅÈõÜÊàê‰Ω†ÁöÑGPT-SoVITSÊ∫êÁ†ÅÈÄªËæë
        """
        try:
            # TODO: ÈõÜÊàê‰Ω†ÁöÑGPT-SoVITSÊ∫êÁ†Å
            # ‰ª•‰∏ãÊòØÂü∫‰∫éÊ∫êÁ†ÅÁöÑ‰º™‰ª£Á†ÅÂÆûÁé∞Ê°ÜÊû∂

            # 1. Âä†ËΩΩÊ®°ÂûãÊùÉÈáç
            # gpt_dict = torch.load(gpt_path, map_location="cpu")
            # sovits_dict = torch.load(sovits_path, map_location="cpu")

            # 2. ÂàùÂßãÂåñÊ®°ÂûãÔºàÂü∫‰∫é‰Ω†ÁöÑÊ∫êÁ†ÅÔºâ
            # text_encoder = TextEncoder(...)
            # synthesizer = SynthesizerTrn(...)
            # vocoder = ...

            # 3. ÊñáÊú¨È¢ÑÂ§ÑÁêÜ
            # phones, bert_features = preprocess_text(text)

            # 4. ËØ≠‰πâÁºñÁ†Å
            # semantic_tokens = text_encoder.encode(...)

            # 5. Èü≥È¢ëÁîüÊàê
            # audio_features = synthesizer.generate(...)

            # 6. Â£∞Á†ÅÂô®ËΩ¨Êç¢
            # audio_data = vocoder.convert(...)

            # ÁîüÊàêÊ®°ÊãüÈü≥È¢ëÊï∞ÊçÆÂπ∂ÂàõÂª∫WAVÊ†ºÂºè
            sample_rate = 44100
            duration = len(text) * 0.3  # Ê†πÊçÆÊñáÊú¨ÈïøÂ∫¶‰º∞ÁÆóÊó∂ÈïøÔºàÊØèÂ≠óÁ¨¶0.3ÁßíÔºâ
            duration = max(duration, 1.0)  # ÊúÄÂ∞ë1Áßí
            duration = min(duration, 10.0)  # ÊúÄÂ§ö10Áßí

            # ÁîüÊàêÈöèÊú∫Èü≥È¢ëÊï∞ÊçÆÔºàÂÆûÈôÖÂ∫îÁî®‰∏≠Â∫îËØ•ÊòØÊ®°ÂûãÁîüÊàêÁöÑÔºâ
            samples = np.random.randint(
                -32768, 32767,
                size=int(sample_rate * duration),
                dtype=np.int16
            )

            # ÂàõÂª∫WAVÊñá‰ª∂Ê†ºÂºè
            wav_data = self._create_wav_file(samples.tobytes(), sample_rate)

            logger.info(f"üéµ Êé®ÁêÜÂÆåÊàêÔºàÊ®°ÊãüÊï∞ÊçÆÔºâÔºåWAVÊñá‰ª∂Â§ßÂ∞è: {len(wav_data)} bytes")
            return wav_data

        except Exception as e:
            logger.error(f"‚ùå Êé®ÁêÜÊâßË°åÂ§±Ë¥•: {e}")
            return b""

    def _create_wav_file(self, pcm_data: bytes, sample_rate: int = 44100) -> bytes:
        """
        ÂàõÂª∫WAVÊñá‰ª∂Ê†ºÂºè

        Args:
            pcm_data: PCMÈü≥È¢ëÊï∞ÊçÆÔºà16bit, ÂçïÂ£∞ÈÅìÔºâ
            sample_rate: ÈááÊ†∑Áéá

        Returns:
            ÂÆåÊï¥ÁöÑWAVÊñá‰ª∂Êï∞ÊçÆ
        """
        try:
            # WAVÊñá‰ª∂Â§¥ÁªìÊûÑ
            # RIFFÂ§¥
            riff_header = b'RIFF'
            file_size = 36 + len(pcm_data)  # 36ÊòØWAVÂ§¥ÁöÑÂõ∫ÂÆöÂ§ßÂ∞è
            riff_size = file_size.to_bytes(4, 'little')

            # WAVEÊ†áËØÜ
            wave_header = b'WAVE'

            # fmtÂ≠êÂùó
            fmt_header = b'fmt '
            fmt_size = (16).to_bytes(4, 'little')  # fmtÂ≠êÂùóÂ§ßÂ∞è
            audio_format = (1).to_bytes(2, 'little')  # PCMÊ†ºÂºè
            num_channels = (1).to_bytes(2, 'little')  # ÂçïÂ£∞ÈÅì
            sample_rate_bytes = sample_rate.to_bytes(4, 'little')
            byte_rate = (sample_rate * 1 * 16 // 8).to_bytes(4, 'little')  # Â≠óËäÇÁéá
            block_align = (1 * 16 // 8).to_bytes(2, 'little')  # ÂùóÂØπÈΩê
            bits_per_sample = (16).to_bytes(2, 'little')  # 16‰Ωç

            # dataÂ≠êÂùó
            data_header = b'data'
            data_size = len(pcm_data).to_bytes(4, 'little')

            # ÁªÑÂêàÊâÄÊúâÈÉ®ÂàÜ
            wav_file = (
                riff_header + riff_size + wave_header +
                fmt_header + fmt_size + audio_format + num_channels +
                sample_rate_bytes + byte_rate + block_align + bits_per_sample +
                data_header + data_size + pcm_data
            )

            logger.info(f"‚úÖ WAVÊñá‰ª∂ÂàõÂª∫ÊàêÂäü: {len(wav_file)} bytes, ÈááÊ†∑Áéá: {sample_rate}Hz")
            return wav_file

        except Exception as e:
            logger.error(f"‚ùå ÂàõÂª∫WAVÊñá‰ª∂Â§±Ë¥•: {e}")
            return b""

    def _get_role_config(self, role_name: str) -> Optional[Dict]:
        """Ëé∑ÂèñËßíËâ≤ÈÖçÁΩÆ"""
        return self.config.get("role_voice_mapping", {}).get(role_name)

    def get_available_roles(self) -> List[Dict]:
        """Ëé∑ÂèñÂèØÁî®ËßíËâ≤ÂàóË°®"""
        roles = []
        for role_name, config in self.config.get("role_voice_mapping", {}).items():
            roles.append({
                "name": role_name,
                "description": config.get("description", ""),
                "gpt_model": config.get("gpt_model"),
                "sovits_model": config.get("sovits_model"),
                "voice_params": config.get("voice_params", {})
            })
        return roles

    def is_model_available(self, role_name: str) -> bool:
        """Ê£ÄÊü•ËßíËâ≤Ê®°ÂûãÊòØÂê¶ÂèØÁî®"""
        role_config = self._get_role_config(role_name)
        if not role_config:
            return False

        gpt_model = role_config.get("gpt_model")
        sovits_model = role_config.get("sovits_model")

        gpt_path = os.path.join(self.gpt_weights_dir, gpt_model)
        sovits_path = os.path.join(self.sovits_weights_dir, sovits_model)

        return os.path.exists(gpt_path) and os.path.exists(sovits_path)

    async def health_check(self) -> Dict:
        """ÂÅ•Â∫∑Ê£ÄÊü•"""
        try:
            available_roles = self.get_available_roles()
            working_roles = [role for role in available_roles if self.is_model_available(role["name"])]

            return {
                "service": "gpt_sovits",
                "device": self.device,
                "total_roles": len(available_roles),
                "working_roles": len(working_roles),
                "gpt_weights_dir": self.gpt_weights_dir,
                "sovits_weights_dir": self.sovits_weights_dir,
                "models_loaded": len(self.models_cache)
            }

        except Exception as e:
            return {
                "service": "gpt_sovits",
                "error": str(e),
                "device": self.device
            }

# ÂÖ®Â±ÄÊúçÂä°ÂÆû‰æã
gpt_sovits_service = GPTSoVITSService()
